{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yurong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import javalang\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "MODE = \"normal\"  #normal or simple or SBT\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_DIM = 256\n",
    "UNITS = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function：\n",
    "    Input the code token list, comment string，and return whether it's invalid\n",
    "The rule of valid method:\n",
    "    1. code token size <= 100\n",
    "    2. One-sentence-comment（I hope model generate only one sentence.\n",
    "       If training data consist multi-sentence comment, the effect will be bad and the first sentence only can not\n",
    "       properly describe the functionality of the method）\n",
    "\n",
    "PS: I regard \"tester\", \"setter\", \"getter\" and \"constructor\" as valid method\n",
    "'''\n",
    "def is_invalid_method(code, nl):   \n",
    "    tokens_parse = javalang.tokenizer.tokenize(code)\n",
    "    token_len = len(list(tokens_parse))\n",
    "    \n",
    "    if token_len > 350 or len(code.split('\\n')) > 40:\n",
    "        return True\n",
    "    if len(nl.split('.')) != 1 or len(nltk.word_tokenize(nl)) > 30:\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "    \n",
    "    \n",
    "'''\n",
    "Function: \n",
    "    Input the root of AST and the deep of the tree, \n",
    "    it will filter the null value and return the list of SBT (structural-based travesal) and print the tree structure\n",
    "'''\n",
    "def parse_tree(root, deep):\n",
    "    seq = []\n",
    "    seq.extend(['(', str(root).split('(')[0]])\n",
    "    #print('\\t'*(deep)+str(root).split('(')[0])    # show node name\n",
    "    if not hasattr(root, 'attrs'):  # error-handling\n",
    "        return []\n",
    "    for attr in root.attrs:\n",
    "        if eval('root.%s' % attr) in [None, [], \"\", set(), False]:    # filter the null attr\n",
    "            continue\n",
    "        elif isinstance(eval('root.%s' % attr), list):\n",
    "            x = eval('root.%s' % attr)\n",
    "            if not all(elem in x for elem in [None, [], \"\", set(), False]):    # if not all elements in list are null\n",
    "                seq.extend(['(',attr])\n",
    "                #print('\\t'*(deep+1)+attr)\n",
    "                #deep += 1\n",
    "                for i in eval('root.%s' % attr):    # recursive the list\n",
    "                    if i is None or isinstance(i, str):    # perhaps it has None value in the list\n",
    "                        continue\n",
    "                    #deep += 1\n",
    "                    seq.extend(parse_tree(i, deep))\n",
    "                    \n",
    "                    #deep -= 1\n",
    "                #deep -= 1\n",
    "                seq.extend([')',attr])\n",
    "        elif 'tree' in str(type(eval('root.%s' % attr))):    #if the attr is one kind of Node, recursive the Node\n",
    "            seq.extend(['(',attr])\n",
    "            #print('\\t'*(deep+1)+attr)\n",
    "            #deep += 2\n",
    "            seq.extend(parse_tree(eval('root.%s' % attr), deep))\n",
    "            #deep -= 2\n",
    "            seq.extend([')',attr])\n",
    "        else:\n",
    "            seq.extend(['(','<'+str(attr)+'>_'+str(eval('root.%s' % attr)),')','<'+str(attr)+'>_'+str(eval('root.%s' % attr))])\n",
    "            #exec(\"print('\\t'*(deep+1)+attr+': '+str(root.%s))\" % attr)    #it must be normal attribute\n",
    "    seq.extend([')', str(root).split('(')[0]])\n",
    "    return seq\n",
    "\n",
    "\n",
    "'''\n",
    "Usage:\n",
    "    1. \"camelCase\" -> [\"camel\", \"Case\"]\n",
    "    2. \"snake_case\" -> [\"snake\", \"_\", \"case\"]\n",
    "    3. \"normal\" -> [\"normal\"]\n",
    "'''\n",
    "def split_identifier(id_token):\n",
    "    if  \"_\" in id_token:\n",
    "        return id_token.split(\"_\")\n",
    "    elif id_token != id_token.lower() and id_token != id_token.upper():\n",
    "        matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', id_token)\n",
    "        return [m.group(0) for m in matches]\n",
    "    else:\n",
    "        return [id_token]\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "Usage:\n",
    "    1. input the list of train, test, valid dataset\n",
    "    2. filter the dataset, split it to train, test set and save as the smaller dataset.\n",
    "    3. return the amount of the data from smaller datasets.\n",
    "Example:\n",
    "    filter_dataset(['./data/train.json', './data/test.json'], './data')\n",
    "Note:\n",
    "    The filter method is different from the method in DeepCom, because I have no idea how DeepCom did.\n",
    "    It doesn't make sense that DeepCom could filter so many data via the method mentioned in its paper.\n",
    "'''\n",
    "def filter_dataset(path_list, save_path):\n",
    "    \n",
    "    inputs = []\n",
    "    for path in path_list:\n",
    "        input_file = open(path)\n",
    "        inputs.extend(input_file.readlines())\n",
    "        input_file.close()\n",
    "    outputs = []\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "    output_train_file = open(save_path+'/simplified_train.json', \"w\")\n",
    "    output_test_file = open(save_path+'/simplified_test.json', \"w\")\n",
    "    \n",
    "    print('Original total: '+str(len(inputs)))\n",
    "    for pair in inputs:\n",
    "        pair = json.loads(pair)\n",
    "        if is_invalid_method(pair['code'], pair['nl']):\n",
    "            continue\n",
    "        outputs.append(json.dumps(pair))\n",
    "\n",
    "    random.shuffle(outputs)\n",
    "    print('Final total: '+str(len(outputs)))\n",
    "    print('Data shuffle complete')\n",
    "    train_index = int(len(outputs)*0.9)\n",
    "    test_index = int(len(outputs)-1)\n",
    "    train_output = outputs[:train_index]\n",
    "    test_output = outputs[train_index+1:test_index]\n",
    "    \n",
    "    for row in train_output:\n",
    "        output_train_file.write(row+'\\n')\n",
    "    output_train_file.close()\n",
    "    print('simplified train data finish writing')\n",
    "    for row in test_output:\n",
    "        output_test_file.write(row+'\\n')\n",
    "    output_test_file.close()\n",
    "    print('simplified test data finish writing')\n",
    "\n",
    "\n",
    "    return len(train_output), len(test_output)\n",
    "\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    path: the path of the data you want to read\n",
    "    code_voc: code vocabulary, the data type is list\n",
    "    comment_voc: comment vocabulary, the data type is list\n",
    "    mode: \"simple\" or \"normal\"\n",
    "Return values:\n",
    "    code_tokens, comment_tokens: 2-dimension list, store the code and comment into list, snippet by snippet\n",
    "    code_voc, comment_voc: the all vocabularies in the file of the path, data type is list\n",
    "Note:\n",
    "    It hasn't used SBT in DeepCom.\n",
    "TODO:\n",
    "    Change the rare words in comments into other common words via pre-trained embedding\n",
    "'''\n",
    "def readdata(path, code_voc, comment_voc, mode):\n",
    "    input_file = open(path)\n",
    "    inputs = input_file.readlines()\n",
    "\n",
    "    code_tokens = []          # code_tokens = ['<START>', '<Modifier>', 'public', '<Identifier>',....]\n",
    "    comment_tokens = []       # comment_tokens = []\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    #=============== extract comment part of the snippet ==========================\n",
    "    print(\"comment tokenizing...\")\n",
    "    for index, pair in enumerate(inputs):\n",
    "        pair = json.loads(pair)\n",
    "        tokens = nltk.word_tokenize(pair['nl'])\n",
    "        tokens.append('<END>')\n",
    "        comment_tokens.append(tokens)\n",
    "        for x in tokens:\n",
    "            if x not in comment_voc:\n",
    "                comment_voc.append(x)\n",
    "    \n",
    "    # =============== extract the code part of the snippet =========================\n",
    "    if mode==\"SBT\":\n",
    "        token_count = dict()\n",
    "\n",
    "        # count the code tokens\n",
    "        print(\"counting tokens...\")\n",
    "        for index, pair in enumerate(inputs):\n",
    "            if index%20000 == 0 and index != 0:\n",
    "                print(index)\n",
    "            pair = json.loads(pair)\n",
    "            parsed_inputs = code_tokenize(pair['code'], mode)\n",
    "            \n",
    "            inputs[index] = parsed_inputs\n",
    "            if len(parsed_inputs) == 0:  # error-handling due to dirty data when SBT mode\n",
    "                continue\n",
    "            \n",
    "            for x in parsed_inputs:\n",
    "                if x not in token_count:\n",
    "                    token_count[x] = 1\n",
    "                else:\n",
    "                    token_count[x] += 1\n",
    "\n",
    "        # select most frequency 30000 voc\n",
    "        typename = ['<modifiers>', '<member>', '<value>', '<name>', '<operator>', '<qualifier>']\n",
    "        code_voc.extend(typename)\n",
    "        for w in sorted(token_count, key=token_count.get, reverse=True)[:30000-len(code_voc)]:\n",
    "            code_voc.append(w) \n",
    "            \n",
    "        print('token processing...')\n",
    "        # <SimpleName>_extractFor -> <SimpleName>, if <SimpleName>_extractFor is outside 30000 voc\n",
    "        for index, parsed_inputs in enumerate(inputs):\n",
    "            if index%20000 == 0 and index != 0:\n",
    "                print(index)\n",
    "            if len(parsed_inputs) == 0:  \n",
    "                continue\n",
    "            for index2 in range(len(parsed_inputs)):\n",
    "                if parsed_inputs[index2] not in code_voc:\n",
    "                    tmp = parsed_inputs[index2].split('_')\n",
    "                    if len(tmp) > 1 and tmp[0] in typename:\n",
    "                        parsed_inputs[index2] = tmp[0]\n",
    "                    else:\n",
    "                        parsed_inputs[index2] = \"<UNK>\"\n",
    "            code_tokens.append(parsed_inputs)\n",
    "            \n",
    "\n",
    "    elif mode == \"simple\" or mode == \"normal\":\n",
    "        print(\"code tokenizing...\")\n",
    "        for index, pair in enumerate(inputs):\n",
    "            if index%20000 == 0 and index != 0:\n",
    "                print(index)\n",
    "            pair = json.loads(pair)\n",
    "            parsed_inputs = code_tokenize(pair['code'], mode)\n",
    "\n",
    "            for x in parsed_inputs:\n",
    "                if x not in code_voc:\n",
    "                    code_voc.append(x)\n",
    "            code_tokens.append(parsed_inputs)\n",
    "        \n",
    "\n",
    "    print('readdata:')\n",
    "    print('\\tdata amount: '+str(len(code_tokens)))\n",
    "    print('\\trun time: '+str(time.time()-start))\n",
    "\n",
    "    input_file.close()\n",
    "    return code_tokens, comment_tokens, code_voc, comment_voc\n",
    "\n",
    "\n",
    "'''\n",
    "Usage:\n",
    "    Transform the token to the index in vocabulary\n",
    "    ['<START>', '<Modifier>', 'public', ..., '<Separator>', ';', '<Separator>', '}', '<END>']\n",
    "    => [0, 7, 8, ..., 14, 29, 14, 30, 1]\n",
    "Parameter data type: \n",
    "    2-dimension list\n",
    "Return data type:\n",
    "    2-dimension list\n",
    "'''\n",
    "def token2index(lst, voc):\n",
    "    for index, seq in enumerate(lst):\n",
    "        seq_index = []\n",
    "        for token in seq:\n",
    "            seq_index.append(voc.index(token))\n",
    "        lst[index] = seq_index\n",
    "    return lst\n",
    "\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    lst: the list of sequences to be padded\n",
    "    pad_data: the value you want to pad\n",
    "Return type:\n",
    "    numpy array\n",
    "'''\n",
    "def pad_sequences(lst, pad_data):\n",
    "    maxlen = max(len(x) for x in lst)\n",
    "    for index, seq in enumerate(lst):\n",
    "        lst[index].extend([pad_data] * (maxlen-len(seq)))\n",
    "    return np.array(lst)\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    x: the list of data\n",
    "    batch_sz: batch size\n",
    "Return shape:\n",
    "    [None, batch_sz, None]\n",
    "Example:\n",
    "    a = [1,2,3,4,5,6,7,8,9,10]\n",
    "    a = getBatch(x=a, batch_sz=3)\n",
    "    a\n",
    "    ---output---\n",
    "    [[1,2,3], [4,5,6], [7,8,9]]\n",
    "'''\n",
    "def getBatch(x, batch_sz):\n",
    "    dataset = []\n",
    "    while(len(x)>=batch_sz):\n",
    "        dataset.append(x[:batch_sz])\n",
    "        x = x[batch_sz:]\n",
    "    if type(x) == np.ndarray:\n",
    "        return np.array(dataset)\n",
    "    elif type(x) == list:\n",
    "        return dataset\n",
    "    \n",
    "def ngram(words, n):\n",
    "    return list(zip(*(words[i:] for i in range(n))))\n",
    "\n",
    "\n",
    "#  bleu4 (n=4)\n",
    "def bleu(true, pred, n):\n",
    "    true = nltk.word_tokenize(true)\n",
    "    pred = nltk.word_tokenize(pred)\n",
    "    c = len(pred)\n",
    "    r = len(true)\n",
    "    bp = 1. if c > r else np.exp(1 - r / (c + 1e-10))\n",
    "    score = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        true_ngram = set(ngram(true, i))\n",
    "        pred_ngram = ngram(pred, i)\n",
    "        if len(true_ngram)==0 or len(true_ngram)==0:\n",
    "            break\n",
    "        length = float(len(pred_ngram)) + 1e-10\n",
    "        count = sum([1. if t in true_ngram else 0. for t in pred_ngram])\n",
    "        score += math.log(1e-10 + (count / length))\n",
    "    score = math.exp(score / n)  #n就是公式的Wn\n",
    "    bleu = bp * score\n",
    "    return bleu\n",
    "\n",
    "\n",
    "def evaluate(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, mode):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    inputs = code_tokenize(code, mode)\n",
    "    \n",
    "    if mode==\"simple\" or mode==\"normal\":\n",
    "        for index, token in enumerate(inputs):\n",
    "            if token not in code_voc:\n",
    "                inputs[index] = code_voc.index('<UNK>')\n",
    "            else:\n",
    "                inputs[index] = code_voc.index(token)\n",
    "                \n",
    "    elif mode==\"SBT\":\n",
    "        typename = ['<modifiers>', '<member>', '<value>', '<name>', '<operator>', '<qualifier>']\n",
    "        for index, token in enumerate(inputs):\n",
    "            if token not in code_voc:\n",
    "                tmp = token.split('_')\n",
    "                if len(tmp) > 1 and tmp[0] in typename:\n",
    "                    inputs[index] = code_voc.index(tmp[0])\n",
    "                else:\n",
    "                    inputs[index] = code_voc.index(\"<UNK>\")\n",
    "            else:\n",
    "                inputs[index] = code_voc.index(token)\n",
    "    \n",
    "    \n",
    "    inputs += [code_voc.index('<PAD>')] * (max_length_inp - len(inputs))\n",
    "    inputs = np.array(inputs)\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    hidden_h, hidden_c = tf.zeros((1, UNITS)), tf.zeros((1, UNITS))\n",
    "    hidden = [hidden_h, hidden_c]\n",
    "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inputs, hidden)\n",
    "    dec_hidden = [enc_hidden_h, enc_hidden_c]\n",
    "    \n",
    "    dec_input = tf.expand_dims([comment_voc.index('<START>')], 1)       \n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden_h, dec_hidden_c, attention_weights = decoder(dec_input, dec_hidden, enc_output)\n",
    "        dec_hidden = [dec_hidden_h, dec_hidden_c]\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        if comment_voc[predicted_id] == '<END>':\n",
    "            return result, code, attention_plot\n",
    "        \n",
    "        result += comment_voc[predicted_id] + ' '\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, code, attention_plot\n",
    "\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    sns.set()\n",
    "    fig, ax = plt.subplots(figsize=(20,10)) \n",
    "    sns.heatmap(attention, xticklabels=sentence, yticklabels=predicted_sentence, ax=ax)\n",
    "    \n",
    "\n",
    "def translate(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, mode):\n",
    "    result, code, attention_plot = evaluate(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, mode)\n",
    "    return result\n",
    "\n",
    "def code_tokenize(code, mode):\n",
    "    inputs = []\n",
    "    if mode ==\"simple\":\n",
    "        tokens_parse = javalang.tokenizer.tokenize(code)\n",
    "        for token in tokens_parse:    # iterate the tokens of the sentence\n",
    "            token = str(token).split(' ')\n",
    "            splitted_id = split_identifier(token[1].strip('\"'))    # split the camelCase and snake_case\n",
    "            inputs.extend(splitted_id)\n",
    "    elif mode == \"normal\":\n",
    "        tokens_parse = javalang.tokenizer.tokenize(code)\n",
    "        for token in tokens_parse:    # iterate the tokens of the sentence\n",
    "            token = str(token).split(' ')\n",
    "            splitted_id = split_identifier(token[1].strip('\"'))    # split the camelCase and snake_case\n",
    "            temp = ['<'+token[0]+'>']    # token[0] is token type, token[1] is token value\n",
    "            temp.extend(splitted_id)\n",
    "            inputs.extend(temp)\n",
    "            \n",
    "    elif mode == \"SBT\":\n",
    "        tree = javalang.parse.parse('class aa {'+code+'}')\n",
    "        _, node = list(tree)[2]    # 前兩個用來篩掉class aa{ }的部分\n",
    "        inputs = parse_tree(node, 0)\n",
    "        if len(inputs) == 0:   # error-handling due to dirty data\n",
    "            return []\n",
    "\n",
    "    inputs.insert(0, '<START>')\n",
    "    inputs.append('<END>')\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "\n",
    "'''\n",
    "用途：把一個二維的array做機率正規化\n",
    "例如：[[3,4,5],[1,2,3]] -> [[0.25, 0.33, 0.416], [0.167, 0.333, 0.5]]\n",
    "'''\n",
    "def distribution(arr):\n",
    "    new_arr = []\n",
    "    for i in arr:\n",
    "        tmp = []\n",
    "        total = sum(i)\n",
    "        for x in i:\n",
    "            tmp.append(x/total)\n",
    "        new_arr.append(tmp)\n",
    "    return np.array(new_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis the big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 588108\n",
      "avg loc : 12.934027423534452\n",
      "max loc : 2860\n",
      "\n",
      "Level 1: 0.67\n",
      "Level 2: 0.86\n",
      "Level 3: 0.92\n",
      "Level 4: 0.95\n",
      "Level 5: 0.97\n",
      "Level 6: 0.98\n",
      "Level 7: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = []\n",
    "for path in ['./data/train.json', './data/test.json', './data/valid.json']:\n",
    "    input_file = open(path)\n",
    "    inputs.extend(input_file.readlines())\n",
    "    input_file.close()\n",
    "\n",
    "avgloc = 0\n",
    "locLevel = {'1':0, '2':0, '3':0, '4':0, '5':0, '6':0, '7':0}  # loc level {0~10, 10~20, ..., 50~60, 60up}\n",
    "maxloc = 0\n",
    "maxkey = 0\n",
    "\n",
    "print('total data: ' + str(len(inputs)))\n",
    "for key, pair in enumerate(inputs):\n",
    "    pair = json.loads(pair)\n",
    "    loc = len(pair['code'].split('\\n'))\n",
    "    avgloc += loc\n",
    "    if loc >= 60:\n",
    "        locLevel['7'] += 1\n",
    "    else:\n",
    "        locLevel[str(math.ceil(loc/10))] += 1\n",
    "    if loc > maxloc:\n",
    "        maxloc = loc\n",
    "        maxkey = key\n",
    "\n",
    "avgloc = avgloc/len(inputs)\n",
    "\n",
    "print('avg loc : '+str(avgloc))\n",
    "print('max loc : '+str(maxloc),end='\\n\\n')\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "percent_cnt = []\n",
    "percent_cnt2 = []\n",
    "for i in range(7):\n",
    "    cnt += locLevel[str(i+1)]\n",
    "    percent_cnt.append(round(cnt/len(inputs), 2))\n",
    "    percent_cnt2.append((locLevel[str(i+1)]/len(inputs))*100)\n",
    "    print('Level '+str(i+1)+': '+str(round(cnt/len(inputs), 2)))\n",
    "\n",
    "\n",
    "objects = ('0~10', '10~20', '20~30', '30~40', '40~50', '50~60', 'above 60')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(y_pos, percent_cnt2, color=\"g\", align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.xlabel('LOC')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('LOC distribution of big dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the original big dataset into simpler and better dataset\n",
    "* #### Size of training set, testing set and valid set ->  (81932, 10241, 10241)\n",
    "* #### If you already have \"simplified_train.json\", \"simplified_test.json\" and \"simplified_valid.json\", then you can skip this code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total: 529297\n",
      "Final total: 119235\n",
      "Data shuffle complete\n",
      "simplified train data finish writing\n",
      "simplified test data finish writing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107311, 11922)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dataset(['./data/train.json', './data/test.json'], './simplified_dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading training data (it costs about below 10 mins)\n",
    "* #### If you already have 'train_data.pkl', you can skip this code cell below and directly read 'train_normal_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment tokenizing...\n",
      "code tokenizing...\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "readdata:\n",
      "\tdata amount: 107311\n",
      "\trun time: 378.522577047348\n",
      "size of code vocabulary:  67722\n",
      "size of comment vocabulary:  35812\n"
     ]
    }
   ],
   "source": [
    "code_voc = ['<PAD>','<START>','<END>','<UNK>']\n",
    "comment_voc = ['<PAD>','<START>','<END>','<UNK>']\n",
    "code_train, comment_train, code_voc, comment_voc = readdata('./simplified_dataset/simplified_train.json', code_voc, comment_voc, MODE)\n",
    "\n",
    "code_train = token2index(code_train, code_voc)\n",
    "comment_train = token2index(comment_train, comment_voc)\n",
    "code_train = pad_sequences(code_train, code_voc.index('<PAD>'))\n",
    "comment_train = pad_sequences(comment_train, comment_voc.index('<PAD>'))\n",
    "\n",
    "print('size of code vocabulary: ', len(code_voc))\n",
    "print('size of comment vocabulary: ', len(comment_voc))\n",
    "\n",
    "# Saving the training data:\n",
    "if MODE==\"normal\":\n",
    "    pkl_filename = \"./simplified_dataset/train_normal_data.pkl\"\n",
    "elif MODE==\"simple\":\n",
    "    pkl_filename = \"./simplified_dataset/train_simple_data.pkl\"\n",
    "elif MODE==\"SBT\":\n",
    "    pkl_filename = \"train_SBT_data.pkl\"\n",
    "    \n",
    "with open(pkl_filename, 'wb') as f:\n",
    "    pickle.dump([code_train, comment_train, code_voc, comment_voc], f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the pickle file of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of code vocabulary:  67722\n",
      "size of comment vocabulary:  35812\n"
     ]
    }
   ],
   "source": [
    "# Getting back the training data:\n",
    "if MODE==\"normal\":\n",
    "    with open('./simplified_dataset/train_normal_data.pkl', 'rb') as f:\n",
    "        code_train, comment_train, code_voc, comment_voc = pickle.load(f)\n",
    "elif MODE==\"simple\":\n",
    "    with open('./simplified_dataset/train_simple_data.pkl', 'rb') as f:\n",
    "        code_train, comment_train, code_voc, comment_voc = pickle.load(f)\n",
    "elif MODE==\"SBT\":\n",
    "    with open('./simplified_dataset/train_SBT_data.pkl', 'rb') as f:\n",
    "        code_train, comment_train, code_voc, comment_voc = pickle.load(f)\n",
    "    \n",
    "print('size of code vocabulary: ', len(code_voc))\n",
    "print('size of comment vocabulary: ', len(comment_voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just test the functionality of transforming source code to SBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('./data/test.json')\n",
    "inputs = input_file.readlines()\n",
    "pair = json.loads(inputs[0])\n",
    "tree = javalang.parse.parse('class aa {'+pair['code']+'}')\n",
    "print(pair['code'], end='\\n')\n",
    "\n",
    "_, node = list(tree)[2]    # 前兩個用來篩掉class aa{ }的部分\n",
    "seq = parse_tree(node, 0)\n",
    "for i in seq:\n",
    "    print(i,end='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the deep learing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(units):\n",
    "    return tf.keras.layers.LSTM(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = lstm(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state_h, state_c = self.lstm(x, initial_state = hidden)        \n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = lstm(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden[1], 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state_h, state_c = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state_h, state_c, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units)), tf.zeros((self.batch_sz, self.dec_units))\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some parameters and build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(code_train)\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "\n",
    "vocab_inp_size = len(code_voc)\n",
    "vocab_tar_size = len(comment_voc)\n",
    "\n",
    "max_length_inp = max(len(t) for t in code_train)\n",
    "max_length_targ = max(len(t) for t in comment_train)\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=1e-3)  #tensorflow 2.0\n",
    "\n",
    "\n",
    "#if not os.path.exists('./training_checkpoints'):\n",
    "#    os.makedirs('./training_checkpoints')\n",
    "# ==== set the checkpoint =======\n",
    "if MODE==\"normal\":\n",
    "    checkpoint_dir = './training_checkpoints/adam-normal-256-60epochs'\n",
    "elif MODE==\"simple\":\n",
    "    checkpoint_dir = './training_checkpoints/adam-simple-256-60epochs'\n",
    "elif MODE==\"SBT\":\n",
    "    checkpoint_dir = './training_checkpoints/adam-SBT-256-80epochs'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "lossArray = np.array([])\n",
    "testAccuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the testing set to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./simplified_dataset/simplified_test.json')\n",
    "inputs = f.readlines()\n",
    "f.close()\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "\n",
    "for pair in inputs:\n",
    "    pair = json.loads(pair)\n",
    "    test_inputs.append(pair['code'])\n",
    "    test_outputs.append(pair['nl'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for 1 epoch 3878.166503429413 sec\n",
      "\n",
      "Epoch 1 Loss 1.6881  Testing accuracy 0.1084\n",
      "Epoch 8 Loss 0.9116  Testing accuracy 0.2562\n",
      "Epoch 9 Loss 0.8623  Testing accuracy 0.2631\n",
      "Epoch 10 Loss 0.8176  Testing accuracy 0.2765\n",
      "Epoch 11 Loss 0.7771  Testing accuracy 0.2933\n",
      "Epoch 12 Loss 0.7396  Testing accuracy 0.2986\n",
      "Epoch 13 Loss 0.7057  Testing accuracy 0.3051\n",
      "Epoch 14 Loss 0.6731  Testing accuracy 0.3150\n",
      "Epoch 15 Loss 0.6436  Testing accuracy 0.3190\n",
      "Epoch 18 Loss 0.5659  Testing accuracy 0.3390\n",
      "Epoch 19 Loss 0.5429  Testing accuracy 0.3458\n",
      "Epoch 20 Loss 0.5217  Testing accuracy 0.3477\n",
      "Epoch 21 Loss 0.5016  Testing accuracy 0.3585\n",
      "Epoch 29 Loss 0.3770  Testing accuracy 0.3802\n",
      "Epoch 32 Loss 0.3439  Testing accuracy 0.3810\n",
      "Epoch 33 Loss 0.3335  Testing accuracy 0.3875\n",
      "Epoch 34 Loss 0.3228  Testing accuracy 0.3880\n",
      "Epoch 36 Loss 0.3063  Testing accuracy 0.3932\n",
      "Epoch 38 Loss 0.2924  Testing accuracy 0.3948\n",
      "Epoch 39 Loss 0.2801  Testing accuracy 0.3952\n",
      "Epoch 40 Loss 0.2730  Testing accuracy 0.3891\n",
      "Epoch 41 Loss 0.2777  Testing accuracy 0.3976\n",
      "Epoch 42 Loss 0.2627  Testing accuracy 0.3956\n",
      "Epoch 52 Loss 0.2048  Testing accuracy 0.4040\n",
      "Epoch 54 Loss 0.1961  Testing accuracy 0.4070\n",
      "Epoch 55 Loss 0.1923  Testing accuracy 0.4047\n",
      "Epoch 60 Loss 0.1748  Testing accuracy 0.4037\n",
      "Epoch 62 Loss 0.1685  Testing accuracy 0.4101\n",
      "Epoch 63 Loss 0.1649  Testing accuracy 0.4096\n",
      "Epoch 64 Loss 0.1699  Testing accuracy 0.4018\n",
      "Epoch 65 Loss 0.1629  Testing accuracy 0.4026\n",
      "Epoch 66 Loss 0.1828  Testing accuracy 0.4130\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-36057235046d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         message=\"Converting sparse IndexedSlices to a dense Tensor.*\")\n\u001b[0;32m--> 613\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    479\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m         \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#EPOCHS = 0\n",
    "epoch = 0\n",
    "early_stop_count = 0\n",
    "\n",
    "#for epoch in range(EPOCHS):\n",
    "while (True):\n",
    "    start = time.time()\n",
    "\n",
    "    hidden_h, hidden_c = encoder.initialize_hidden_state()\n",
    "\n",
    "    hidden = [hidden_h, hidden_c]\n",
    "\n",
    "    total_loss = 0 \n",
    "\n",
    "    code_train_batch = getBatch(code_train, BATCH_SIZE)\n",
    "\n",
    "    comment_train_batch = getBatch(comment_train, BATCH_SIZE)\n",
    "\n",
    "    dataset = [(code_train_batch[i], comment_train_batch[i]) for i in range(0, len(code_train_batch))]\n",
    "\n",
    "    np.random.shuffle(dataset)\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, hidden)\n",
    "\n",
    "            dec_hidden = [enc_hidden_h, enc_hidden_c]\n",
    "\n",
    "            dec_input = tf.expand_dims([comment_voc.index('<START>')] * BATCH_SIZE, 1)       \n",
    "\n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(0, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden_h, dec_hidden_c, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "                dec_hidden = [dec_hidden_h, dec_hidden_c]\n",
    "\n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        variables = encoder.variables + decoder.variables\n",
    "\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "    lossArray = np.append(lossArray, (total_loss / N_BATCH) )    \n",
    "    \n",
    "    \n",
    "    # calculate test accuracy\n",
    "    total_bleu = 0\n",
    "    for index, test in enumerate(test_inputs):\n",
    "        predict = translate(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE)\n",
    "        bleu_score = bleu(test_outputs[index], predict, 1)\n",
    "        total_bleu += bleu_score\n",
    "\n",
    "    total_bleu = total_bleu / len(test_inputs)\n",
    "    testAccuracy.append(total_bleu)\n",
    "    if total_bleu < testAccuracy[-1]:\n",
    "        early_stop_count += 1\n",
    "        if early_stop_count == 3:\n",
    "            break\n",
    "    \n",
    "\n",
    "    if epoch == 0:\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    print('Epoch {} Loss {:.4f}  Testing accuracy {:.4f}'.format(epoch + 1, total_loss / N_BATCH, total_bleu))\n",
    "\n",
    "    \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "# ======= recording the hyper-parameters of the models ===========\n",
    "f_parameter = open(checkpoint_dir+\"/parameters\", \"a\")\n",
    "f_parameter.write(\"EPOCHS=\"+str(epoch)+\"\\n\")\n",
    "f_parameter.write(\"BATCH_SIZE=\"+str(BATCH_SIZE)+\"\\n\")\n",
    "f_parameter.write(\"DATA=\"+MODE+\"\\n\")\n",
    "f_parameter.write(\"OPTIMIZER=\"+\"ADAM\"+\"\\n\")\n",
    "f_parameter.write(\"EMBEDDING=\"+str(EMBEDDING_DIM)+\"\\n\")\n",
    "f_parameter.write(\"UNITS=\"+str(UNITS)+\"\\n\")\n",
    "#f_parameter.write(\"LOSS=\"+str(list(lossArray))+\"\\n\")\n",
    "f_parameter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the learning curve of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, epoch+1), lossArray, \"b\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(MODE+\" version model training loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, epoch+1), testAccuracy, \"r\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(MODE+\" version model testing accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.10844131668540452,\n",
       " 0.15520609862446483,\n",
       " 0.19041410025404873,\n",
       " 0.20622469240592955,\n",
       " 0.22323646716541323,\n",
       " 0.23970722647271447,\n",
       " 0.24198094412488375,\n",
       " 0.25620605198601804,\n",
       " 0.26311518819858765,\n",
       " 0.27645576171360564,\n",
       " 0.29332707635046995,\n",
       " 0.2985801605829906,\n",
       " 0.3051149051429068,\n",
       " 0.31496735193109693,\n",
       " 0.3189555395951241,\n",
       " 0.32926818291142484,\n",
       " 0.33534596002373657,\n",
       " 0.338950122125037,\n",
       " 0.34582578439975137,\n",
       " 0.34774981667162036,\n",
       " 0.358520432644826,\n",
       " 0.3603126772603762,\n",
       " 0.35877952112476186,\n",
       " 0.36436672290960676,\n",
       " 0.3661203211981899,\n",
       " 0.3739679706955937,\n",
       " 0.3721685372478941,\n",
       " 0.3765770005336589,\n",
       " 0.38020660748942436,\n",
       " 0.3793857385813053,\n",
       " 0.3801081642318112,\n",
       " 0.38096447196713346,\n",
       " 0.3874604992989694,\n",
       " 0.38802056109675503,\n",
       " 0.3900739722884812,\n",
       " 0.3932164674477807,\n",
       " 0.3901590228154351,\n",
       " 0.3948071392879618,\n",
       " 0.3952420725950689,\n",
       " 0.38911924507103623,\n",
       " 0.3976280320338771,\n",
       " 0.39558425008725306,\n",
       " 0.3957168509506138,\n",
       " 0.40257498851603435,\n",
       " 0.3977150543160333,\n",
       " 0.40171688581935366,\n",
       " 0.39936069118926615,\n",
       " 0.4004938199371627,\n",
       " 0.39639834675718333,\n",
       " 0.39962375239777853,\n",
       " 0.40549656444037036,\n",
       " 0.40404878952223167,\n",
       " 0.40593284898577764,\n",
       " 0.40701749036364854,\n",
       " 0.40466284782721773,\n",
       " 0.40579620741143674,\n",
       " 0.40782954105254654,\n",
       " 0.40677889192265776,\n",
       " 0.4067036825740945,\n",
       " 0.4036590049917754,\n",
       " 0.40531780308489634,\n",
       " 0.4100509559375066,\n",
       " 0.40956475320902375,\n",
       " 0.4017819963794683,\n",
       " 0.4026398015932255,\n",
       " 0.412967754058086,\n",
       " 0.40777303447327706,\n",
       " 0.40837766531652353,\n",
       " 0.41200054020077903,\n",
       " 0.40749710482956286,\n",
       " 0.410769549482009,\n",
       " 0.4116341973540011,\n",
       " 0.4123267901964778]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f990f776978>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model via BLEU4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "bleu3: 0.3271\n"
     ]
    }
   ],
   "source": [
    "total_bleu = 0\n",
    "for index, test in enumerate(test_inputs):\n",
    "    predict = translate(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE)\n",
    "    bleu_score = bleu(test_outputs[index], predict, 3)\n",
    "    total_bleu += bleu_score\n",
    "    if (index%1000) == 0:\n",
    "        print(index)\n",
    "        \n",
    "total_bleu = total_bleu / len(test_inputs)\n",
    "print(\"bleu3:\",round(total_bleu, 4))\n",
    "\n",
    "f_parameter = open(checkpoint_dir+\"/parameters\", \"a\")\n",
    "f_parameter.write(\"BLEU3=\"+str(round(total_bleu, 4))+\"\\n\")\n",
    "f_parameter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the comment of one snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "private void summarizeChecks(){\n",
      "  if (serverReply == CheckResult.PASSED && sdCardWritable == CheckResult.PASSED) {\n",
      "    looper();\n",
      "  }\n",
      " else   if (serverReply == CheckResult.FAILED) {\n",
      "    if (mBadPasswordFlag) {\n",
      "      final int id=toExport.size() > 0 ? toExport.get(0) : RadioBeacon.SESSION_NOT_TRACKING;\n",
      "      onUploadFailed(id,getResources().getString(R.string.warning_bad_password));\n",
      "    }\n",
      " else {\n",
      "      final int id=toExport.size() > 0 ? toExport.get(0) : RadioBeacon.SESSION_NOT_TRACKING;\n",
      "      onUploadFailed(id,getResources().getString(R.string.warning_outdated_client));\n",
      "    }\n",
      "  }\n",
      " else   if (serverReply == CheckResult.UNKNOWN) {\n",
      "    final int id=toExport.size() > 0 ? toExport.get(0) : RadioBeacon.SESSION_NOT_TRACKING;\n",
      "    onUploadFailed(id,getResources().getString(R.string.warning_client_version_not_checked));\n",
      "  }\n",
      " else   if (sdCardWritable == CheckResult.FAILED) {\n",
      "    final int id=toExport.size() > 0 ? toExport.get(0) : RadioBeacon.SESSION_NOT_TRACKING;\n",
      "    onUploadFailed(id,getResources().getString(R.string.warning_sd_not_writable));\n",
      "  }\n",
      " else {\n",
      "    final int id=toExport.size() > 0 ? toExport.get(0) : RadioBeacon.SESSION_NOT_TRACKING;\n",
      "    onUploadFailed(id,\"Unknown error\");\n",
      "  }\n",
      "}\n",
      "\n",
      "Original comment:  Evaluates whether sanity checks (first + second round) are good, before starting export\n",
      "Predicted translation:  This is callbed by higher \n",
      "bleu4: 0.0000\n"
     ]
    }
   ],
   "source": [
    "index = 33\n",
    "print(test_inputs[index], end=\"\\n\")\n",
    "print(\"Original comment: \",test_outputs[index], end=\"\\n\")\n",
    "predict = translate(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE)\n",
    "print(\"Predicted translation: \", predict, end=\"\\n\")\n",
    "bleu4_score = bleu(test_outputs[index], predict, 4)\n",
    "print(\"bleu4: {:.4f}\".format(bleu4_score), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
