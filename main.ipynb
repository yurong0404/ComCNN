{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yurong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import javalang\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "MODE = \"SBT\"  #normal or simple or SBT\n",
    "BATCH_SIZE = 32\n",
    "EMBEDDING_DIM = 256\n",
    "UNITS = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function：\n",
    "    Input the code token list, comment string，and return whether it's invalid\n",
    "The rule of valid method:\n",
    "    1. code token size <= 100\n",
    "    2. One-sentence-comment（I hope model generate only one sentence.\n",
    "       If training data consist multi-sentence comment, the effect will be bad and the first sentence only can not\n",
    "       properly describe the functionality of the method）\n",
    "\n",
    "PS: I regard \"tester\", \"setter\", \"getter\" and \"constructor\" as valid method\n",
    "'''\n",
    "def is_invalid_method(code, nl):   \n",
    "    tokens_parse = javalang.tokenizer.tokenize(code)\n",
    "    token_len = len(list(tokens_parse))\n",
    "    \n",
    "    if token_len > 350 or len(code.split('\\n')) > 40:\n",
    "        return True\n",
    "    if len(nl.split('.')) != 1 or len(nltk.word_tokenize(nl)) > 30:\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "    \n",
    "    \n",
    "'''\n",
    "Function: \n",
    "    Input the root of AST and the deep of the tree, \n",
    "    it will filter the null value and return the list of SBT (structural-based travesal) and print the tree structure\n",
    "'''\n",
    "def parse_tree(root, deep):\n",
    "    seq = []\n",
    "    seq.extend(['(', str(root).split('(')[0]])\n",
    "    #print('\\t'*(deep)+str(root).split('(')[0])    # show node name\n",
    "    if not hasattr(root, 'attrs'):  # error-handling\n",
    "        return []\n",
    "    for attr in root.attrs:\n",
    "        if eval('root.%s' % attr) in [None, [], \"\", set(), False]:    # filter the null attr\n",
    "            continue\n",
    "        elif isinstance(eval('root.%s' % attr), list):\n",
    "            x = eval('root.%s' % attr)\n",
    "            if not all(elem in x for elem in [None, [], \"\", set(), False]):    # if not all elements in list are null\n",
    "                seq.extend(['(',attr])\n",
    "                #print('\\t'*(deep+1)+attr)\n",
    "                #deep += 1\n",
    "                for i in eval('root.%s' % attr):    # recursive the list\n",
    "                    if i is None or isinstance(i, str):    # perhaps it has None value in the list\n",
    "                        continue\n",
    "                    #deep += 1\n",
    "                    seq.extend(parse_tree(i, deep))\n",
    "                    \n",
    "                    #deep -= 1\n",
    "                #deep -= 1\n",
    "                seq.extend([')',attr])\n",
    "        elif 'tree' in str(type(eval('root.%s' % attr))):    #if the attr is one kind of Node, recursive the Node\n",
    "            seq.extend(['(',attr])\n",
    "            #print('\\t'*(deep+1)+attr)\n",
    "            #deep += 2\n",
    "            seq.extend(parse_tree(eval('root.%s' % attr), deep))\n",
    "            #deep -= 2\n",
    "            seq.extend([')',attr])\n",
    "        else:\n",
    "            seq.extend(['(','<'+str(attr)+'>_'+str(eval('root.%s' % attr)),')','<'+str(attr)+'>_'+str(eval('root.%s' % attr))])\n",
    "            #exec(\"print('\\t'*(deep+1)+attr+': '+str(root.%s))\" % attr)    #it must be normal attribute\n",
    "    seq.extend([')', str(root).split('(')[0]])\n",
    "    return seq\n",
    "\n",
    "\n",
    "'''\n",
    "Usage:\n",
    "    1. \"camelCase\" -> [\"camel\", \"Case\"]\n",
    "    2. \"snake_case\" -> [\"snake\", \"_\", \"case\"]\n",
    "    3. \"normal\" -> [\"normal\"]\n",
    "'''\n",
    "def split_identifier(id_token):\n",
    "    if  \"_\" in id_token:\n",
    "        return id_token.split(\"_\")\n",
    "    elif id_token != id_token.lower() and id_token != id_token.upper():\n",
    "        matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', id_token)\n",
    "        return [m.group(0) for m in matches]\n",
    "    else:\n",
    "        return [id_token]\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "Usage:\n",
    "    1. input the list of train, test, valid dataset\n",
    "    2. filter the dataset, split it to train, test set and save as the smaller dataset.\n",
    "    3. return the amount of the data from smaller datasets.\n",
    "Example:\n",
    "    filter_dataset(['./data/train.json', './data/test.json'], './data')\n",
    "Note:\n",
    "    The filter method is different from the method in DeepCom, because I have no idea how DeepCom did.\n",
    "    It doesn't make sense that DeepCom could filter so many data via the method mentioned in its paper.\n",
    "'''\n",
    "def filter_dataset(path_list, save_path):\n",
    "    \n",
    "    inputs = []\n",
    "    for path in path_list:\n",
    "        input_file = open(path)\n",
    "        inputs.extend(input_file.readlines())\n",
    "        input_file.close()\n",
    "    outputs = []\n",
    "    \n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "    output_train_file = open(save_path+'/simplified_train.json', \"w\")\n",
    "    output_test_file = open(save_path+'/simplified_test.json', \"w\")\n",
    "    \n",
    "    print('Original total: '+str(len(inputs)))\n",
    "    for pair in inputs:\n",
    "        pair = json.loads(pair)\n",
    "        if is_invalid_method(pair['code'], pair['nl']):\n",
    "            continue\n",
    "        outputs.append(json.dumps(pair))\n",
    "\n",
    "    random.shuffle(outputs)\n",
    "    print('Final total: '+str(len(outputs)))\n",
    "    print('Data shuffle complete')\n",
    "    train_index = int(len(outputs)*0.9)\n",
    "    test_index = int(len(outputs)-1)\n",
    "    train_output = outputs[:train_index]\n",
    "    test_output = outputs[train_index+1:test_index]\n",
    "    \n",
    "    for row in train_output:\n",
    "        output_train_file.write(row+'\\n')\n",
    "    output_train_file.close()\n",
    "    print('simplified train data finish writing')\n",
    "    for row in test_output:\n",
    "        output_test_file.write(row+'\\n')\n",
    "    output_test_file.close()\n",
    "    print('simplified test data finish writing')\n",
    "\n",
    "\n",
    "    return len(train_output), len(test_output)\n",
    "\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    path: the path of the data you want to read\n",
    "    code_voc: code vocabulary, the data type is list\n",
    "    comment_voc: comment vocabulary, the data type is list\n",
    "    mode: \"simple\" or \"normal\"\n",
    "Return values:\n",
    "    code_tokens, comment_tokens: 2-dimension list, store the code and comment into list, snippet by snippet\n",
    "    code_voc, comment_voc: the all vocabularies in the file of the path, data type is list\n",
    "Note:\n",
    "    It hasn't used SBT in DeepCom.\n",
    "TODO:\n",
    "    Change the rare words in comments into other common words via pre-trained embedding\n",
    "'''\n",
    "def readdata(path, code_voc, comment_voc, mode):\n",
    "    input_file = open(path)\n",
    "    inputs = input_file.readlines()\n",
    "\n",
    "    code_tokens = []          # code_tokens = ['<START>', '<Modifier>', 'public', '<Identifier>',....]\n",
    "    comment_tokens = []       # comment_tokens = []\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    #=============== extract comment part of the snippet ==========================\n",
    "    print(\"comment tokenizing...\")\n",
    "    for index, pair in enumerate(inputs):\n",
    "        pair = json.loads(pair)\n",
    "        tokens = nltk.word_tokenize(pair['nl'])\n",
    "        tokens.append('<END>')\n",
    "        comment_tokens.append(tokens)\n",
    "        for x in tokens:\n",
    "            if x not in comment_voc:\n",
    "                comment_voc.append(x)\n",
    "    \n",
    "    # =============== extract the code part of the snippet =========================\n",
    "    if mode==\"SBT\":\n",
    "        token_count = dict()\n",
    "\n",
    "        # count the code tokens\n",
    "        print(\"counting tokens...\")\n",
    "        for index, pair in enumerate(inputs):\n",
    "            if index%20000 == 0 and index != 0:\n",
    "                print(index)\n",
    "            pair = json.loads(pair)\n",
    "            parsed_inputs = code_tokenize(pair['code'], mode)\n",
    "            \n",
    "            inputs[index] = parsed_inputs\n",
    "            if len(parsed_inputs) == 0:  # error-handling due to dirty data when SBT mode\n",
    "                continue\n",
    "            \n",
    "            for x in parsed_inputs:\n",
    "                if x not in token_count:\n",
    "                    token_count[x] = 1\n",
    "                else:\n",
    "                    token_count[x] += 1\n",
    "\n",
    "        # select most frequency 30000 voc\n",
    "        typename = ['<modifiers>', '<member>', '<value>', '<name>', '<operator>', '<qualifier>']\n",
    "        code_voc.extend(typename)\n",
    "        for w in sorted(token_count, key=token_count.get, reverse=True)[:30000-len(code_voc)]:\n",
    "            code_voc.append(w) \n",
    "            \n",
    "        print('token processing...')\n",
    "        # <SimpleName>_extractFor -> <SimpleName>, if <SimpleName>_extractFor is outside 30000 voc\n",
    "        for index, parsed_inputs in enumerate(inputs):\n",
    "            if index%20000 == 0 and index != 0:\n",
    "                print(index)\n",
    "            if len(parsed_inputs) == 0:  \n",
    "                continue\n",
    "            for index2 in range(len(parsed_inputs)):\n",
    "                if parsed_inputs[index2] not in code_voc:\n",
    "                    tmp = parsed_inputs[index2].split('_')\n",
    "                    if len(tmp) > 1 and tmp[0] in typename:\n",
    "                        parsed_inputs[index2] = tmp[0]\n",
    "                    else:\n",
    "                        parsed_inputs[index2] = \"<UNK>\"\n",
    "            code_tokens.append(parsed_inputs)\n",
    "            \n",
    "\n",
    "    elif mode == \"simple\" or mode == \"normal\":\n",
    "        print(\"code tokenizing...\")\n",
    "        for index, pair in enumerate(inputs):\n",
    "            if index%20000 == 0 and index != 0:\n",
    "                print(index)\n",
    "            pair = json.loads(pair)\n",
    "            parsed_inputs = code_tokenize(pair['code'], mode)\n",
    "\n",
    "            for x in parsed_inputs:\n",
    "                if x not in code_voc:\n",
    "                    code_voc.append(x)\n",
    "            code_tokens.append(parsed_inputs)\n",
    "        \n",
    "\n",
    "    print('readdata:')\n",
    "    print('\\tdata amount: '+str(len(code_tokens)))\n",
    "    print('\\trun time: '+str(time.time()-start))\n",
    "\n",
    "    input_file.close()\n",
    "    return code_tokens, comment_tokens, code_voc, comment_voc\n",
    "\n",
    "\n",
    "'''\n",
    "Usage:\n",
    "    Transform the token to the index in vocabulary\n",
    "    ['<START>', '<Modifier>', 'public', ..., '<Separator>', ';', '<Separator>', '}', '<END>']\n",
    "    => [0, 7, 8, ..., 14, 29, 14, 30, 1]\n",
    "Parameter data type: \n",
    "    2-dimension list\n",
    "Return data type:\n",
    "    2-dimension list\n",
    "'''\n",
    "def token2index(lst, voc):\n",
    "    for index, seq in enumerate(lst):\n",
    "        seq_index = []\n",
    "        for token in seq:\n",
    "            seq_index.append(voc.index(token))\n",
    "        lst[index] = seq_index\n",
    "    return lst\n",
    "\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    lst: the list of sequences to be padded\n",
    "    pad_data: the value you want to pad\n",
    "Return type:\n",
    "    numpy array\n",
    "'''\n",
    "def pad_sequences(lst, pad_data):\n",
    "    maxlen = max(len(x) for x in lst)\n",
    "    for index, seq in enumerate(lst):\n",
    "        lst[index].extend([pad_data] * (maxlen-len(seq)))\n",
    "    return np.array(lst)\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    x: the list of data\n",
    "    batch_sz: batch size\n",
    "Return shape:\n",
    "    [None, batch_sz, None]\n",
    "Example:\n",
    "    a = [1,2,3,4,5,6,7,8,9,10]\n",
    "    a = getBatch(x=a, batch_sz=3)\n",
    "    a\n",
    "    ---output---\n",
    "    [[1,2,3], [4,5,6], [7,8,9]]\n",
    "'''\n",
    "def getBatch(x, batch_sz):\n",
    "    dataset = []\n",
    "    while(len(x)>=batch_sz):\n",
    "        dataset.append(x[:batch_sz])\n",
    "        x = x[batch_sz:]\n",
    "    if type(x) == np.ndarray:\n",
    "        return np.array(dataset)\n",
    "    elif type(x) == list:\n",
    "        return dataset\n",
    "    \n",
    "def ngram(words, n):\n",
    "    return list(zip(*(words[i:] for i in range(n))))\n",
    "\n",
    "\n",
    "#  bleu4 (n=4)\n",
    "def bleu(true, pred, n):\n",
    "    true = nltk.word_tokenize(true)\n",
    "    pred = nltk.word_tokenize(pred)\n",
    "    c = len(pred)\n",
    "    r = len(true)\n",
    "    bp = 1. if c > r else np.exp(1 - r / (c + 1e-10))\n",
    "    score = 0\n",
    "    \n",
    "    for i in range(1, n+1):\n",
    "        true_ngram = set(ngram(true, i))\n",
    "        pred_ngram = ngram(pred, i)\n",
    "        if len(true_ngram)==0 or len(true_ngram)==0:\n",
    "            break\n",
    "        length = float(len(pred_ngram)) + 1e-10\n",
    "        count = sum([1. if t in true_ngram else 0. for t in pred_ngram])\n",
    "        score += math.log(1e-10 + (count / length))\n",
    "    score = math.exp(score / n)  #n就是公式的Wn\n",
    "    bleu = bp * score\n",
    "    return bleu\n",
    "\n",
    "\n",
    "def code_to_index(inputs, code_voc, max_length_inp, mode):\n",
    "    if mode==\"simple\" or mode==\"normal\":\n",
    "        for index, token in enumerate(inputs):\n",
    "            if token not in code_voc:\n",
    "                inputs[index] = code_voc.index('<UNK>')\n",
    "            else:\n",
    "                inputs[index] = code_voc.index(token)\n",
    "                \n",
    "    elif mode==\"SBT\":\n",
    "        typename = ['<modifiers>', '<member>', '<value>', '<name>', '<operator>', '<qualifier>']\n",
    "        for index, token in enumerate(inputs):\n",
    "            if token not in code_voc:\n",
    "                tmp = token.split('_')\n",
    "                if len(tmp) > 1 and tmp[0] in typename:\n",
    "                    inputs[index] = code_voc.index(tmp[0])\n",
    "                else:\n",
    "                    inputs[index] = code_voc.index(\"<UNK>\")\n",
    "            else:\n",
    "                inputs[index] = code_voc.index(token)\n",
    "                \n",
    "    inputs += [code_voc.index('<PAD>')] * (max_length_inp - len(inputs))\n",
    "    inputs = np.array(inputs)\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "\n",
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    sns.set()\n",
    "    fig, ax = plt.subplots(figsize=(20,10)) \n",
    "    sns.heatmap(attention, xticklabels=sentence, yticklabels=predicted_sentence, ax=ax)\n",
    "    \n",
    "\n",
    "def code_tokenize(code, mode):\n",
    "    inputs = []\n",
    "    if mode ==\"simple\":\n",
    "        tokens_parse = javalang.tokenizer.tokenize(code)\n",
    "        for token in tokens_parse:    # iterate the tokens of the sentence\n",
    "            token = str(token).split(' ')\n",
    "            splitted_id = split_identifier(token[1].strip('\"'))    # split the camelCase and snake_case\n",
    "            inputs.extend(splitted_id)\n",
    "    elif mode == \"normal\":\n",
    "        tokens_parse = javalang.tokenizer.tokenize(code)\n",
    "        for token in tokens_parse:    # iterate the tokens of the sentence\n",
    "            token = str(token).split(' ')\n",
    "            splitted_id = split_identifier(token[1].strip('\"'))    # split the camelCase and snake_case\n",
    "            temp = ['<'+token[0]+'>']    # token[0] is token type, token[1] is token value\n",
    "            temp.extend(splitted_id)\n",
    "            inputs.extend(temp)\n",
    "            \n",
    "    elif mode == \"SBT\":\n",
    "        tree = javalang.parse.parse('class aa {'+code+'}')\n",
    "        _, node = list(tree)[2]    # 前兩個用來篩掉class aa{ }的部分\n",
    "        inputs = parse_tree(node, 0)\n",
    "        if len(inputs) == 0:   # error-handling due to dirty data\n",
    "            return []\n",
    "\n",
    "    inputs.insert(0, '<START>')\n",
    "    inputs.append('<END>')\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "\n",
    "'''\n",
    "用途：把一個二維的array做機率正規化\n",
    "例如：[[3,4,5],[1,2,3]] -> [[0.25, 0.33, 0.416], [0.167, 0.333, 0.5]]\n",
    "'''\n",
    "def distribution(arr):\n",
    "    new_arr = []\n",
    "    for i in arr:\n",
    "        tmp = []\n",
    "        total = sum(i)\n",
    "        for x in i:\n",
    "            tmp.append(x/total)\n",
    "        new_arr.append(tmp)\n",
    "    return np.array(new_arr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis the big dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data: 588108\n",
      "avg loc : 12.934027423534452\n",
      "max loc : 2860\n",
      "\n",
      "Level 1: 0.67\n",
      "Level 2: 0.86\n",
      "Level 3: 0.92\n",
      "Level 4: 0.95\n",
      "Level 5: 0.97\n",
      "Level 6: 0.98\n",
      "Level 7: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = []\n",
    "for path in ['./data/train.json', './data/test.json', './data/valid.json']:\n",
    "    input_file = open(path)\n",
    "    inputs.extend(input_file.readlines())\n",
    "    input_file.close()\n",
    "\n",
    "avgloc = 0\n",
    "locLevel = {'1':0, '2':0, '3':0, '4':0, '5':0, '6':0, '7':0}  # loc level {0~10, 10~20, ..., 50~60, 60up}\n",
    "maxloc = 0\n",
    "maxkey = 0\n",
    "\n",
    "print('total data: ' + str(len(inputs)))\n",
    "for key, pair in enumerate(inputs):\n",
    "    pair = json.loads(pair)\n",
    "    loc = len(pair['code'].split('\\n'))\n",
    "    avgloc += loc\n",
    "    if loc >= 60:\n",
    "        locLevel['7'] += 1\n",
    "    else:\n",
    "        locLevel[str(math.ceil(loc/10))] += 1\n",
    "    if loc > maxloc:\n",
    "        maxloc = loc\n",
    "        maxkey = key\n",
    "\n",
    "avgloc = avgloc/len(inputs)\n",
    "\n",
    "print('avg loc : '+str(avgloc))\n",
    "print('max loc : '+str(maxloc),end='\\n\\n')\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "percent_cnt = []\n",
    "percent_cnt2 = []\n",
    "for i in range(7):\n",
    "    cnt += locLevel[str(i+1)]\n",
    "    percent_cnt.append(round(cnt/len(inputs), 2))\n",
    "    percent_cnt2.append((locLevel[str(i+1)]/len(inputs))*100)\n",
    "    print('Level '+str(i+1)+': '+str(round(cnt/len(inputs), 2)))\n",
    "\n",
    "\n",
    "objects = ('0~10', '10~20', '20~30', '30~40', '40~50', '50~60', 'above 60')\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(y_pos, percent_cnt2, color=\"g\", align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.xlabel('LOC')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('LOC distribution of big dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the original big dataset into simpler and better dataset\n",
    "* #### Size of training set, testing set and valid set ->  (81932, 10241, 10241)\n",
    "* #### If you already have \"simplified_train.json\", \"simplified_test.json\" and \"simplified_valid.json\", then you can skip this code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total: 529297\n",
      "Final total: 119235\n",
      "Data shuffle complete\n",
      "simplified train data finish writing\n",
      "simplified test data finish writing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(107311, 11922)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dataset(['./data/train.json', './data/test.json'], './simplified_dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading training data (it costs about below 10 mins)\n",
    "* #### If you already have 'train_data.pkl', you can skip this code cell below and directly read 'train_normal_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment tokenizing...\n",
      "code tokenizing...\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n",
      "readdata:\n",
      "\tdata amount: 107311\n",
      "\trun time: 331.9519696235657\n",
      "size of code vocabulary:  67706\n",
      "size of comment vocabulary:  35812\n"
     ]
    }
   ],
   "source": [
    "code_voc = ['<PAD>','<START>','<END>','<UNK>']\n",
    "comment_voc = ['<PAD>','<START>','<END>','<UNK>']\n",
    "code_train, comment_train, code_voc, comment_voc = readdata('./simplified_dataset/simplified_train.json', code_voc, comment_voc, MODE)\n",
    "\n",
    "code_train = token2index(code_train, code_voc)\n",
    "comment_train = token2index(comment_train, comment_voc)\n",
    "code_train = pad_sequences(code_train, code_voc.index('<PAD>'))\n",
    "comment_train = pad_sequences(comment_train, comment_voc.index('<PAD>'))\n",
    "\n",
    "print('size of code vocabulary: ', len(code_voc))\n",
    "print('size of comment vocabulary: ', len(comment_voc))\n",
    "\n",
    "# Saving the training data:\n",
    "if MODE==\"normal\":\n",
    "    pkl_filename = \"./simplified_dataset/train_normal_data.pkl\"\n",
    "elif MODE==\"simple\":\n",
    "    pkl_filename = \"./simplified_dataset/train_simple_data.pkl\"\n",
    "elif MODE==\"SBT\":\n",
    "    pkl_filename = \"./simplified_dataset/train_SBT_data.pkl\"\n",
    "    \n",
    "with open(pkl_filename, 'wb') as f:\n",
    "    pickle.dump([code_train, comment_train, code_voc, comment_voc], f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the pickle file of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of code vocabulary:  30000\n",
      "size of comment vocabulary:  35812\n"
     ]
    }
   ],
   "source": [
    "# Getting back the training data:\n",
    "if MODE==\"normal\":\n",
    "    with open('./simplified_dataset/train_normal_data.pkl', 'rb') as f:\n",
    "        code_train, comment_train, code_voc, comment_voc = pickle.load(f)\n",
    "elif MODE==\"simple\":\n",
    "    with open('./simplified_dataset/train_simple_data.pkl', 'rb') as f:\n",
    "        code_train, comment_train, code_voc, comment_voc = pickle.load(f)\n",
    "elif MODE==\"SBT\":\n",
    "    with open('./simplified_dataset/train_SBT_data.pkl', 'rb') as f:\n",
    "        code_train, comment_train, code_voc, comment_voc = pickle.load(f)\n",
    "    \n",
    "print('size of code vocabulary: ', len(code_voc))\n",
    "print('size of comment vocabulary: ', len(comment_voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just test the functionality of transforming source code to SBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('./data/test.json')\n",
    "inputs = input_file.readlines()\n",
    "pair = json.loads(inputs[0])\n",
    "tree = javalang.parse.parse('class aa {'+pair['code']+'}')\n",
    "print(pair['code'], end='\\n')\n",
    "\n",
    "_, node = list(tree)[2]    # 前兩個用來篩掉class aa{ }的部分\n",
    "seq = parse_tree(node, 0)\n",
    "for i in seq:\n",
    "    print(i,end='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the deep learing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(units):\n",
    "    return tf.keras.layers.LSTM(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = lstm(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state_h, state_c = self.lstm(x, initial_state = hidden)        \n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = lstm(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden[1], 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state_h, state_c = self.lstm(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state_h, state_c, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units)), tf.zeros((self.batch_sz, self.dec_units))\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set some parameters and build the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(code_train)\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "\n",
    "vocab_inp_size = len(code_voc)\n",
    "vocab_tar_size = len(comment_voc)\n",
    "\n",
    "max_length_inp = max(len(t) for t in code_train)\n",
    "max_length_targ = max(len(t) for t in comment_train)\n",
    "\n",
    "encoder = Encoder(vocab_inp_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, EMBEDDING_DIM, UNITS, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=1e-3)  #tensorflow 2.0\n",
    "\n",
    "\n",
    "#if not os.path.exists('./training_checkpoints'):\n",
    "#    os.makedirs('./training_checkpoints')\n",
    "# ==== set the checkpoint =======\n",
    "if MODE==\"normal\":\n",
    "    checkpoint_dir = './training_checkpoints/adam-normal-256'\n",
    "elif MODE==\"simple\":\n",
    "    checkpoint_dir = './training_checkpoints/adam-simple-256'\n",
    "elif MODE==\"SBT\":\n",
    "    checkpoint_dir = './training_checkpoints/adam-SBT-256'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "lossArray = np.array([])\n",
    "testAccuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the testing set to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./simplified_dataset/simplified_test.json')\n",
    "inputs = f.readlines()\n",
    "f.close()\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "\n",
    "for pair in inputs:\n",
    "    pair = json.loads(pair)\n",
    "    test_inputs.append(pair['code'])\n",
    "    test_outputs.append(pair['nl'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss 0.6673  Testing accuracy 0.3609\n",
      "Epoch 11 Loss 0.6220  Testing accuracy 0.3688\n",
      "Epoch 12 Loss 0.5793  Testing accuracy 0.3785\n",
      "Epoch 13 Loss 0.5428  Testing accuracy 0.3838\n",
      "Epoch 14 Loss 0.5080  Testing accuracy 0.3904\n",
      "Epoch 15 Loss 0.4772  Testing accuracy 0.3942\n",
      "Epoch 23 Loss 0.3121  Testing accuracy 0.4232\n",
      "Epoch 27 Loss 0.2596  Testing accuracy 0.4303\n",
      "Epoch 28 Loss 0.2462  Testing accuracy 0.4336\n",
      "Epoch 31 Loss 0.2213  Testing accuracy 0.4321\n",
      "Epoch 33 Loss 0.2055  Testing accuracy 0.4365\n",
      "Epoch 34 Loss 0.1945  Testing accuracy 0.4382\n",
      "Epoch 35 Loss 0.1872  Testing accuracy 0.4357\n",
      "Epoch 48 Loss 0.1246  Testing accuracy 0.4438\n",
      "Epoch 50 Loss 0.1190  Testing accuracy 0.4329\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f77fe28d70c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mtotal_bleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_voc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_voc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mtotal_bleu\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-358f0d56e0e8>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, mode)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_voc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_voc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode_voc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment_voc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-358f0d56e0e8>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, mode)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length_targ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m         \u001b[0mdec_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdec_hidden_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_hidden_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b6f1414d0d57>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, hidden, enc_output)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mhidden_with_time_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_with_time_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m       \u001b[0;31m# Broadcasting is required for the inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m       \u001b[0;31m# Reshape the output back to the original ndim of the input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes, name)\u001b[0m\n\u001b[1;32m   4075\u001b[0m     b_reshape, b_free_dims, b_free_dims_static = _tensordot_reshape(\n\u001b[1;32m   4076\u001b[0m         b, b_axes, True)\n\u001b[0;32m-> 4077\u001b[0;31m     \u001b[0mab_matmul\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_reshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4079\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mab_matmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_free_dims\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb_free_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2763\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2764\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2765\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6110\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6111\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6112\u001b[0;31m         transpose_a, \"transpose_b\", transpose_b)\n\u001b[0m\u001b[1;32m   6113\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6114\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "\n",
    "for epoch in range(epoch+1,epoch+70+1):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    hidden_h, hidden_c = encoder.initialize_hidden_state()\n",
    "\n",
    "    hidden = [hidden_h, hidden_c]\n",
    "\n",
    "    total_loss = 0 \n",
    "\n",
    "    code_train_batch = getBatch(code_train, BATCH_SIZE)\n",
    "\n",
    "    comment_train_batch = getBatch(comment_train, BATCH_SIZE)\n",
    "\n",
    "    dataset = [(code_train_batch[i], comment_train_batch[i]) for i in range(0, len(code_train_batch))]\n",
    "\n",
    "    np.random.shuffle(dataset)\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, hidden)\n",
    "\n",
    "            dec_hidden = [enc_hidden_h, enc_hidden_c]\n",
    "\n",
    "            dec_input = tf.expand_dims([comment_voc.index('<START>')] * BATCH_SIZE, 1)       \n",
    "\n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(0, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden_h, dec_hidden_c, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "\n",
    "                dec_hidden = [dec_hidden_h, dec_hidden_c]\n",
    "\n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        variables = encoder.variables + decoder.variables\n",
    "\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "    lossArray = np.append(lossArray, (total_loss / N_BATCH) )    \n",
    "    \n",
    "    \n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    \n",
    "    # calculate test accuracy\n",
    "    total_bleu = 0\n",
    "    for index, test in enumerate(test_inputs):\n",
    "        predict = translate(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE)\n",
    "        bleu_score = bleu(test_outputs[index], predict, 1)\n",
    "        total_bleu += bleu_score\n",
    "    total_bleu = total_bleu / len(test_inputs)\n",
    "    testAccuracy.append(total_bleu)\n",
    "    \n",
    "    \n",
    "    output_f = open(checkpoint_dir+\"/training_log\", \"a\")\n",
    "    if epoch == 1:\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "        output_f.write('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    print('Epoch {} Loss {:.4f}  Testing accuracy {:.4f}'.format(epoch, total_loss / N_BATCH, total_bleu))\n",
    "    output_f.write('Epoch {} Loss {:.4f}  Testing accuracy {:.4f}\\n'.format(epoch, total_loss / N_BATCH, total_bleu))\n",
    "    output_f.close()\n",
    "    \n",
    "    epoch += 1\n",
    "    \n",
    "    \n",
    "# ======= recording the hyper-parameters of the models ===========\n",
    "f_parameter = open(checkpoint_dir+\"/parameters\", \"a\")\n",
    "f_parameter.write(\"EPOCHS=\"+str(epoch)+\"\\n\")\n",
    "f_parameter.write(\"BATCH_SIZE=\"+str(BATCH_SIZE)+\"\\n\")\n",
    "f_parameter.write(\"DATA=\"+MODE+\"\\n\")\n",
    "f_parameter.write(\"OPTIMIZER=\"+\"ADAM\"+\"\\n\")\n",
    "f_parameter.write(\"EMBEDDING=\"+str(EMBEDDING_DIM)+\"\\n\")\n",
    "f_parameter.write(\"UNITS=\"+str(UNITS)+\"\\n\")\n",
    "#f_parameter.write(\"LOSS=\"+str(list(lossArray))+\"\\n\")\n",
    "f_parameter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the learning curve of the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, epoch+1), lossArray, \"b\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(MODE+\" version model training loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, epoch), testAccuracy, \"r\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(MODE+\" version model testing accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0da39513c8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, mode):\n",
    "    \n",
    "    inputs = code_tokenize(code, mode)\n",
    "    inputs = code_to_index(inputs, code_voc, max_length_inp, mode)\n",
    "    \n",
    "    result = ''\n",
    "    \n",
    "    hidden_h, hidden_c = tf.zeros((1, UNITS)), tf.zeros((1, UNITS))\n",
    "    hidden = [hidden_h, hidden_c]\n",
    "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inputs, hidden)\n",
    "    dec_hidden = [enc_hidden_h, enc_hidden_c]\n",
    "    dec_input = tf.expand_dims([comment_voc.index('<START>')], 1)       \n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden_h, dec_hidden_c, attention_weights = decoder(dec_input, dec_hidden, enc_output)\n",
    "        dec_hidden = [dec_hidden_h, dec_hidden_c]\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        if comment_voc[predicted_id] == '<END>':\n",
    "            return result\n",
    "        result += comment_voc[predicted_id] + ' '\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "def beam_search(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, mode, width):\n",
    "    inputs = code_tokenize(code, mode)\n",
    "    inputs = code_to_index(inputs, code_voc, max_length_inp, mode)\n",
    "        \n",
    "    hidden_h, hidden_c = tf.zeros((1, UNITS)), tf.zeros((1, UNITS))\n",
    "    hidden = [hidden_h, hidden_c]\n",
    "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inputs, hidden)\n",
    "    dec_hidden = [enc_hidden_h, enc_hidden_c]\n",
    "    dec_input = tf.expand_dims([comment_voc.index('<START>')], 1)\n",
    "    \n",
    "    dec_input = [dec_input] * width\n",
    "    dec_hidden = [dec_hidden] * width\n",
    "    \n",
    "    result = [''] * width\n",
    "    score = [1] * width\n",
    "    lock = [0] * width\n",
    "    can_score = [1] * (width ** 2)\n",
    "    can_result = [''] * (width ** 2)\n",
    "    can_input = [''] * (width ** 2)\n",
    "    \n",
    "    for t in range(max_length_targ):\n",
    "        can_lock = [0] * (width ** 2)\n",
    "        for i in range(width):\n",
    "            for x in range(width):\n",
    "                can_score[width*i+x] = score[i]\n",
    "                can_result[width*i+x] = result[i]\n",
    "            if lock[i] == 1:\n",
    "                for x in range(width):\n",
    "                    can_lock[width*i+x] = 1\n",
    "                continue\n",
    "                \n",
    "            predictions, dec_hidden_h, dec_hidden_c, attention_weights = decoder(dec_input[i], dec_hidden[i], enc_output)\n",
    "            dec_hidden[i] = [dec_hidden_h, dec_hidden_c]\n",
    "            predictions = tf.nn.softmax(predictions)\n",
    "            topk_score = tf.math.top_k(predictions[0], width)[0]\n",
    "            topk_id = tf.math.top_k(predictions[0], width)[1]\n",
    "            \n",
    "            for x in range(width):\n",
    "                can_score[width*i+x] *= topk_score[x].numpy()\n",
    "                if comment_voc[topk_id[x].numpy()] == '<END>':\n",
    "                    can_lock[width*i+x] = 1\n",
    "                else:\n",
    "                    can_result[width*i+x] += comment_voc[topk_id[x].numpy()] + ' '\n",
    "                    can_input[width*i+x] = topk_id[x].numpy()\n",
    "        \n",
    "        if t == 0:\n",
    "            for x in range(width):\n",
    "                result[x] = can_result[x]\n",
    "                score[x] = can_score[x]\n",
    "                dec_input[x] = tf.expand_dims([can_input[x]], 0)\n",
    "            continue\n",
    "        \n",
    "        sorted_index = sorted(range(len(can_score)), key=lambda k: can_score[k], reverse=True)[:width]\n",
    "        for x in range(width):\n",
    "            result[x] = can_result[sorted_index[x]]\n",
    "            score[x] = can_score[sorted_index[x]]\n",
    "            if can_lock[sorted_index[x]] == 1:\n",
    "                lock[x] = 1\n",
    "            else:\n",
    "                dec_input[x] = tf.expand_dims([can_input[sorted_index[x]]], 0)\n",
    "            dec_hidden[x] = dec_hidden[sorted_index[x]//width]\n",
    "        \n",
    "        if 0 not in lock:\n",
    "            break\n",
    "\n",
    "    return result[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model via BLEU4 (greedy search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "bleu4: 0.3414\n"
     ]
    }
   ],
   "source": [
    "total_bleu = 0\n",
    "for index, test in enumerate(test_inputs):\n",
    "    predict = translate(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE)\n",
    "    bleu_score = bleu(test_outputs[index], predict, 4)\n",
    "    total_bleu += bleu_score\n",
    "    if (index%2000) == 0:\n",
    "        print(index)\n",
    "        \n",
    "total_bleu = total_bleu / len(test_inputs)\n",
    "print(\"bleu4:\",round(total_bleu, 4))\n",
    "\n",
    "f_parameter = open(checkpoint_dir+\"/parameters\", \"a\")\n",
    "f_parameter.write(\"BLEU4=\"+str(round(total_bleu, 4))+\"\\n\")\n",
    "f_parameter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model via BLEU (beam search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "except\n",
      "10000\n",
      "except\n",
      "Beam search(k=5) bleu4: 0.2709\n"
     ]
    }
   ],
   "source": [
    "total_bleu = 0\n",
    "for index, test in enumerate(test_inputs):\n",
    "    try:\n",
    "        predict = beam_search(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE, 5)\n",
    "    except:\n",
    "        print(\"except\")\n",
    "    bleu_score = bleu(test_outputs[index], predict, 4)\n",
    "    total_bleu += bleu_score\n",
    "    if (index%2000) == 0:\n",
    "        print(index)\n",
    "        \n",
    "total_bleu = total_bleu / len(test_inputs)\n",
    "print(\"Beam search(k=5) bleu4:\",round(total_bleu, 4))\n",
    "\n",
    "f_parameter = open(checkpoint_dir+\"/parameters\", \"a\")\n",
    "f_parameter.write(\"Beam search(k=5) BLEU4=\"+str(round(total_bleu, 4))+\"\\n\")\n",
    "f_parameter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the comment of one snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protected int lengthOfByteStream(jmri.jmrix.AbstractMRMessage m){\n",
      "  int len=m.getNumDataElements() + 2;\n",
      "  return len;\n",
      "}\n",
      "\n",
      "Original comment:  Determine how many bytes the entire message will take, including space for header and trailer\n",
      "Greedy search prediction:  Determine how much many bytes the entire message will take , including space for header and trailer \n",
      "Beam search prediction (k=3):  Determine how much many bytes the entire message will take , including space for header and trailer \n",
      "bleu1: 0.9412\n"
     ]
    }
   ],
   "source": [
    "index = 66\n",
    "print(test_inputs[index], end=\"\\n\")\n",
    "print(\"Original comment: \",test_outputs[index], end=\"\\n\")\n",
    "predict = translate(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE)\n",
    "print(\"Greedy search prediction: \", predict, end=\"\\n\")\n",
    "predict = beam_search(test_inputs[index], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ, MODE, 3)\n",
    "print(\"Beam search prediction (k=3): \", predict, end=\"\\n\")\n",
    "bleu4_score = bleu(test_outputs[index], predict, 1)\n",
    "print(\"bleu1: {:.4f}\".format(bleu4_score), end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
