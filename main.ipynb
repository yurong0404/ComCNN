{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yurong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import javalang\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "#tf.enable_eager_execution() \n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function：\n",
    "    Input the code token list, comment string，and return whether it's invalid\n",
    "The rule of valid method:\n",
    "    1. code token size <= 100\n",
    "    2. One-sentence-comment（I hope model generate only one sentence.\n",
    "       If training data consist multi-sentence comment, the effect will be bad and the first sentence only can not\n",
    "       properly describe the functionality of the method）\n",
    "\n",
    "PS: I regard \"tester\", \"setter\", \"getter\" and \"constructor\" as valid method\n",
    "'''\n",
    "def is_invalid_method(token_len, nl):   \n",
    "    if token_len > 100:\n",
    "        return True\n",
    "    if len(nl.split('.')) != 1 or len(nltk.word_tokenize(nl)) > 30:\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "Function: \n",
    "    Input the root of AST and the deep of the tree, \n",
    "    it will filter the null value and return the list of SBT (structural-based travesal) and print the tree structure\n",
    "'''\n",
    "def parse_tree(root, deep):\n",
    "\n",
    "    seq = []\n",
    "    seq.extend(['(', str(root).split('(')[0]])\n",
    "    #print('\\t'*(deep)+str(root).split('(')[0])    # show node name\n",
    "    for attr in root.attrs:\n",
    "        if eval('root.%s' % attr) in [None, [], \"\", set(), False]:    # filter the null attr\n",
    "            continue\n",
    "        elif isinstance(eval('root.%s' % attr), list):\n",
    "            x = eval('root.%s' % attr)\n",
    "            if not all(elem in x for elem in [None, [], \"\", set(), False]):    # if not all elements in list are null\n",
    "                seq.extend(['(',attr])\n",
    "                #print('\\t'*(deep+1)+attr)\n",
    "                #deep += 1\n",
    "                for i in eval('root.%s' % attr):    # recursive the list\n",
    "                    if i is None or isinstance(i, str):    # perhaps it has None value in the list\n",
    "                        continue\n",
    "                    #deep += 1\n",
    "                    seq.extend(parse_tree(i, deep))\n",
    "                    \n",
    "                    #deep -= 1\n",
    "                #deep -= 1\n",
    "                seq.extend([')',attr])\n",
    "        elif 'tree' in str(type(eval('root.%s' % attr))):    #if the attr is one kind of Node, recursive the Node\n",
    "            seq.extend(['(',attr])\n",
    "            #print('\\t'*(deep+1)+attr)\n",
    "            #deep += 2\n",
    "            seq.extend(parse_tree(eval('root.%s' % attr), deep))\n",
    "            #deep -= 2\n",
    "            seq.extend([')',attr])\n",
    "        else:\n",
    "            seq.extend(['(','<'+str(attr)+'>_'+str(eval('root.%s' % attr)),')','<'+str(attr)+'>_'+str(eval('root.%s' % attr))])\n",
    "            #exec(\"print('\\t'*(deep+1)+attr+': '+str(root.%s))\" % attr)    #it must be normal attribute\n",
    "    seq.extend([')', str(root).split('(')[0]])\n",
    "    return seq\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Function:\n",
    "    1. \"camelCase\" -> [\"camel\", \"Case\"]\n",
    "    2. \"under_score\" -> [\"under\", \"_\", \"score\"]\n",
    "    3. \"normal\" -> [\"normal\"]\n",
    "'''\n",
    "def split_identifier(id_token):\n",
    "    if  \"_\" in id_token:\n",
    "        return id_token.split(\"_\")\n",
    "    elif id_token != id_token.lower() and id_token != id_token.upper():\n",
    "        matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', id_token)\n",
    "        return [m.group(0) for m in matches]\n",
    "    else:\n",
    "        return [id_token]\n",
    "\n",
    "    \n",
    "    \n",
    "'''\n",
    "Function:\n",
    "    1. input the list of train, test, valid dataset\n",
    "    2. filter the dataset, split it to train, test, valid set and save as the smaller dataset.\n",
    "    3. return the amount of the data from smaller datasets.\n",
    "Example:\n",
    "    filter_dataset(['./data/train.json', './data/test.json', './data/valid.json'], './data')\n",
    "Note:\n",
    "    The filter method is different from the method in DeepCom, because I have no idea how DeepCom did.\n",
    "    It doesn't make sense that DeepCom could filter so many data via the method mentioned in its paper.\n",
    "'''\n",
    "def filter_dataset(path_list, save_path):\n",
    "    \n",
    "    inputs = []\n",
    "    for path in path_list:\n",
    "        input_file = open(path)\n",
    "        inputs.extend(input_file.readlines())\n",
    "        input_file.close()\n",
    "    outputs = []\n",
    "    output_train_file = open(save_path+'/filter_train.json', \"w\")\n",
    "    output_test_file = open(save_path+'/filter_test.json', \"w\")\n",
    "    output_valid_file = open(save_path+'/filter_valid.json', \"w\")\n",
    "    \n",
    "    print('Original total: '+str(len(inputs)))\n",
    "    for pair in inputs:\n",
    "        pair = json.loads(pair)\n",
    "        tokens_parse = javalang.tokenizer.tokenize(pair['code'])\n",
    "        if is_invalid_method(len(list(tokens_parse)), pair['nl']):\n",
    "            continue\n",
    "        outputs.append(json.dumps(pair))\n",
    "\n",
    "    random.shuffle(outputs)\n",
    "    print('Final total: '+str(len(outputs)))\n",
    "    print('Data shuffle complete')\n",
    "    train_index = int(len(outputs)*0.8)\n",
    "    test_index = int(len(outputs)*0.9)\n",
    "    train_output = outputs[:train_index]\n",
    "    test_output = outputs[train_index+1:test_index]\n",
    "    valid_output = outputs[test_index+1:]\n",
    "    \n",
    "    for row in train_output:\n",
    "        output_train_file.write(row+'\\n')\n",
    "    output_train_file.close()\n",
    "    print('filter train data finish writing')\n",
    "    for row in test_output:\n",
    "        output_test_file.write(row+'\\n')\n",
    "    output_test_file.close()\n",
    "    print('filter test data finish writing')\n",
    "    for row in valid_output:\n",
    "        output_valid_file.write(row+'\\n')\n",
    "    print('filter valid data finish writing')\n",
    "    output_valid_file.close()\n",
    "\n",
    "    return len(train_output), len(test_output), len(valid_output)\n",
    "\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    path: the path of the data you want to read\n",
    "    code_voc: code vocabulary, the data type is list\n",
    "    comment_voc: comment vocabulary, the data type is list\n",
    "Return values:\n",
    "    code_tokens, comment_tokens: 2-dimension list, store the code and comment into list, snippet by snippet\n",
    "    code_voc, comment_voc: the all vocabularies in the file of the path, data type is list\n",
    "Note:\n",
    "    It hasn't used SBT in DeepCom.\n",
    "TODO:\n",
    "    Change the rare words in comments into other common words via pre-trained embedding\n",
    "'''\n",
    "def readdata(path, code_voc, comment_voc):\n",
    "    input_file = open(path)\n",
    "    inputs = input_file.readlines()\n",
    "\n",
    "    code_tokens = []          # code_tokens = ['<START>', '<Modifier>', 'public', '<Identifier>',....]\n",
    "    comment_tokens = []       # comment_tokens = []\n",
    "\n",
    "    start = time.time()\n",
    "    for index, pair in enumerate(inputs):\n",
    "        if index%5000 == 0 and index != 0:\n",
    "            print(index)\n",
    "        pair = json.loads(pair)\n",
    "        # =============== extract the code part of the snippet =========================\n",
    "        \n",
    "        #TODO: 以下寫成另一個function，切token的部分\n",
    "        tokens_parse = javalang.tokenizer.tokenize(pair['code'])\n",
    "        tokens = []\n",
    "        for token in tokens_parse:    # iterate the tokens of the sentence\n",
    "            token = str(token).split(' ')\n",
    "            splitted_id = split_identifier(token[1].strip('\"'))    # split the camelCase and under_score\n",
    "            temp = ['<'+token[0]+'>']    # token[0] is token type, token[1] is token value\n",
    "            temp.extend(splitted_id)\n",
    "            tokens.extend(temp)\n",
    "            for x in tokens:\n",
    "                if x not in code_voc:\n",
    "                    code_voc.append(x)\n",
    "        tokens.insert(0, '<START>')\n",
    "        tokens.append('<END>')\n",
    "        code_tokens.append(tokens)\n",
    "        \n",
    "        #=============== extract comment part of the snippet ==========================\n",
    "        tokens = nltk.word_tokenize(pair['nl'])\n",
    "        comment_tokens.append(tokens)\n",
    "        for x in tokens:\n",
    "            if x not in comment_voc:\n",
    "                comment_voc.append(x)\n",
    "\n",
    "    print('readdata:')\n",
    "    print('\\tdata amount: '+str(len(code_tokens)))\n",
    "    print('\\trun time: '+str(time.time()-start))\n",
    "\n",
    "    input_file.close()\n",
    "    return code_tokens, comment_tokens, code_voc, comment_voc\n",
    "\n",
    "\n",
    "'''\n",
    "Usage:\n",
    "    Transform the token to the index in vocabulary\n",
    "    ['<START>', '<Modifier>', 'public', ..., '<Separator>', ';', '<Separator>', '}', '<END>']\n",
    "    => [0, 7, 8, ..., 14, 29, 14, 30, 1]\n",
    "Parameter data type: \n",
    "    2-dimension list\n",
    "Return data type:\n",
    "    2-dimension list\n",
    "'''\n",
    "def token2index(lst, voc):\n",
    "    for index, seq in enumerate(lst):\n",
    "        seq_index = []\n",
    "        for token in seq:\n",
    "            seq_index.append(voc.index(token))\n",
    "        lst[index] = seq_index\n",
    "    return lst\n",
    "\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    lst: the list of sequences to be padded\n",
    "    pad_data: the value you want to pad\n",
    "Return type:\n",
    "    numpy array\n",
    "'''\n",
    "def pad_sequences(lst, pad_data):\n",
    "    maxlen = max(len(x) for x in lst)\n",
    "    for index, seq in enumerate(lst):\n",
    "        lst[index].extend([pad_data] * (maxlen-len(seq)))\n",
    "    return np.array(lst)\n",
    "\n",
    "'''\n",
    "Parameters:\n",
    "    x: the list of data\n",
    "    batch_sz: batch size\n",
    "Return shape:\n",
    "    [None, batch_sz, None]\n",
    "Example:\n",
    "    a = [1,2,3,4,5,6,7,8,9,10]\n",
    "    a = getBatch(x=a, batch_sz=3)\n",
    "    a\n",
    "    ---output---\n",
    "    [[1,2,3], [4,5,6], [7,8,9]]\n",
    "'''\n",
    "def getBatch(x, batch_sz):\n",
    "    dataset = []\n",
    "    while(len(x)>=batch_sz):\n",
    "        dataset.append(x[:batch_sz])\n",
    "        x = x[batch_sz:]\n",
    "    if type(x) == np.ndarray:\n",
    "        return np.array(dataset)\n",
    "    elif type(x) == list:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prune the original big dataset into simpler and better dataset\n",
    "* #### Size of training set, testing set and valid set ->  (81932, 10241, 10241)\n",
    "* #### If you already have \"filter_train.json\", \"filter_test.json\" and \"filter_valid.json\", then you can skip this code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original total: 588108\n",
      "Final total: 101220\n",
      "Data shuffle complete\n",
      "filter train data finish writing\n",
      "filter test data finish writing\n",
      "filter valid data finish writing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80976, 10121, 10121)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_dataset(['./data/train.json', './data/test.json', './data/valid.json'], './filter_dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading training data (it costs about 40 mins)\n",
    "* #### If you already have 'train_data.pkl', you can skip this code cell below and directly read 'train_data.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "readdata:\n",
      "\tdata amount: 80976\n",
      "\trun time: 2230.783646583557\n",
      "size of code vocabulary:  42152\n",
      "size of comment vocabulary:  29404\n"
     ]
    }
   ],
   "source": [
    "code_voc = ['<PAD>','<START>','<END>','<UNK>']\n",
    "comment_voc = ['<PAD>','<START>','<END>','<UNK>']\n",
    "code_train, comment_train, code_voc, comment_voc = readdata('./filter_dataset/filter_train.json', code_voc, comment_voc)\n",
    "#code_test, comment_test, code_voc, comment_voc = readdata('./filter_dataset/filter_test.json', code_voc, comment_voc)\n",
    "code_train = token2index(code_train, code_voc)\n",
    "comment_train = token2index(comment_train, comment_voc)\n",
    "code_train = pad_sequences(code_train, code_voc.index('<PAD>'))\n",
    "comment_train = pad_sequences(comment_train, comment_voc.index('<PAD>'))\n",
    "print('size of code vocabulary: ', len(code_voc))\n",
    "print('size of comment vocabulary: ', len(comment_voc))\n",
    "\n",
    "# Saving the training data:\n",
    "with open('train_data.pkl', 'wb') as f:\n",
    "    pickle.dump([code_train, comment_train, code_voc, comment_voc], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of code vocabulary:  42152\n",
      "size of comment vocabulary:  29404\n"
     ]
    }
   ],
   "source": [
    "# Getting back the training data:\n",
    "with open('train_data.pkl', 'rb') as f:\n",
    "    code_train, comment_train, code_voc, comment_voc = pickle.load(f)\n",
    "    \n",
    "print('size of code vocabulary: ', len(code_voc))\n",
    "print('size of comment vocabulary: ', len(comment_voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just test the functionality of transforming source code to SBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = open('./data/test.json')\n",
    "inputs = input_file.readlines()\n",
    "pair = json.loads(inputs[0])\n",
    "tree = javalang.parse.parse('class aa {'+pair['code']+'}')\n",
    "print(pair['code'], end='\\n')\n",
    "\n",
    "_, node = list(tree)[2]    # 前兩個用來篩掉class aa{ }的部分\n",
    "seq = parse_tree(node, 0)\n",
    "for i in seq:\n",
    "    print(i,end='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(code_train)\n",
    "BATCH_SIZE = 32\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "embedding_dim = 512\n",
    "units = 512\n",
    "vocab_inp_size = len(code_voc)\n",
    "vocab_tar_size = len(comment_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_inp = max(len(t) for t in code_train)\n",
    "max_length_targ = max(len(t) for t in comment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(units):\n",
    "    return tf.keras.layers.LSTM(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = lstm(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state_h, state_c = self.lstm(x, initial_state = hidden)        \n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units)), tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = lstm(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden[1], 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying tanh(FC(EO) + FC(H)) to self.V\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the LSTM\n",
    "        output, state_h, state_c = self.lstm(x)\n",
    "        \n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state_h, state_c, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units)), tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "optimizer = tf.optimizers.Adam()  #tensorflow 2.0\n",
    "#optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = 1 - np.equal(real, 0)\n",
    "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "lossArray = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.0110\n",
      "Epoch 1 Batch 200 Loss 0.0231\n",
      "Epoch 2 Batch 800 Loss 0.0281\n",
      "Epoch 2 Batch 1000 Loss 0.0286\n",
      "Epoch 2 Batch 1200 Loss 0.0282\n",
      "Epoch 2 Batch 1400 Loss 0.0332\n",
      "Epoch 2 Batch 1600 Loss 0.0460\n",
      "Epoch 2 Batch 1800 Loss 0.0339\n",
      "Epoch 2 Batch 2000 Loss 0.0425\n",
      "Epoch 2 Batch 2200 Loss 0.0197\n",
      "Epoch 2 Batch 2400 Loss 0.0549\n",
      "Epoch 2 Loss 0.0300\n",
      "Time taken for 1 epoch 2323.9259016513824 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0202\n",
      "Epoch 3 Batch 200 Loss 0.0246\n",
      "Epoch 3 Batch 400 Loss 0.0083\n",
      "Epoch 3 Batch 600 Loss 0.0446\n",
      "Epoch 3 Batch 800 Loss 0.0155\n",
      "Epoch 3 Batch 1000 Loss 0.0460\n",
      "Epoch 3 Batch 1200 Loss 0.0248\n",
      "Epoch 3 Batch 1400 Loss 0.0317\n",
      "Epoch 3 Batch 1600 Loss 0.0219\n",
      "Epoch 3 Batch 1800 Loss 0.0455\n",
      "Epoch 3 Batch 2000 Loss 0.0189\n",
      "Epoch 3 Batch 2200 Loss 0.0506\n",
      "Epoch 3 Batch 2400 Loss 0.0384\n",
      "Epoch 3 Loss 0.0283\n",
      "Time taken for 1 epoch 2320.6367814540863 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0348\n",
      "Epoch 4 Batch 200 Loss 0.0179\n",
      "Epoch 4 Batch 400 Loss 0.0090\n",
      "Epoch 4 Batch 600 Loss 0.0386\n",
      "Epoch 4 Batch 800 Loss 0.0198\n",
      "Epoch 4 Batch 1000 Loss 0.0255\n",
      "Epoch 4 Batch 1200 Loss 0.0297\n",
      "Epoch 4 Batch 1400 Loss 0.0199\n",
      "Epoch 4 Batch 1600 Loss 0.0397\n",
      "Epoch 4 Batch 1800 Loss 0.0289\n",
      "Epoch 4 Batch 2000 Loss 0.0162\n",
      "Epoch 4 Batch 2200 Loss 0.0339\n",
      "Epoch 4 Batch 2400 Loss 0.0262\n",
      "Epoch 4 Loss 0.0273\n",
      "Time taken for 1 epoch 2323.6433334350586 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0325\n",
      "Epoch 5 Batch 200 Loss 0.0200\n",
      "Epoch 5 Batch 400 Loss 0.0108\n",
      "Epoch 5 Batch 600 Loss 0.0291\n",
      "Epoch 5 Batch 800 Loss 0.0297\n",
      "Epoch 5 Batch 1000 Loss 0.0179\n",
      "Epoch 5 Batch 1200 Loss 0.0230\n",
      "Epoch 5 Batch 1400 Loss 0.0521\n",
      "Epoch 5 Batch 1600 Loss 0.0358\n",
      "Epoch 5 Batch 1800 Loss 0.0083\n",
      "Epoch 5 Batch 2000 Loss 0.0114\n",
      "Epoch 5 Batch 2200 Loss 0.0493\n",
      "Epoch 5 Batch 2400 Loss 0.0325\n",
      "Epoch 5 Loss 0.0270\n",
      "Time taken for 1 epoch 2320.2326321601868 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0252\n",
      "Epoch 6 Batch 200 Loss 0.0183\n",
      "Epoch 6 Batch 400 Loss 0.0105\n",
      "Epoch 6 Batch 600 Loss 0.0407\n",
      "Epoch 6 Batch 800 Loss 0.0180\n",
      "Epoch 6 Batch 1000 Loss 0.0198\n",
      "Epoch 6 Batch 1200 Loss 0.0199\n",
      "Epoch 6 Batch 1400 Loss 0.0157\n",
      "Epoch 6 Batch 1600 Loss 0.0311\n",
      "Epoch 6 Batch 1800 Loss 0.0393\n",
      "Epoch 6 Batch 2000 Loss 0.0339\n",
      "Epoch 6 Batch 2200 Loss 0.0466\n",
      "Epoch 6 Batch 2400 Loss 0.0470\n",
      "Epoch 6 Loss 0.0268\n",
      "Time taken for 1 epoch 2333.7023828029633 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0276\n",
      "Epoch 7 Batch 200 Loss 0.0143\n",
      "Epoch 7 Batch 400 Loss 0.0215\n",
      "Epoch 7 Batch 600 Loss 0.0257\n",
      "Epoch 7 Batch 800 Loss 0.0095\n",
      "Epoch 7 Batch 1000 Loss 0.0245\n",
      "Epoch 7 Batch 1200 Loss 0.0263\n",
      "Epoch 7 Batch 1400 Loss 0.0184\n",
      "Epoch 11 Batch 800 Loss 0.0333\n",
      "Epoch 11 Batch 1000 Loss 0.0208\n",
      "Epoch 11 Batch 1200 Loss 0.0336\n",
      "Epoch 11 Batch 1400 Loss 0.0169\n",
      "Epoch 11 Batch 1600 Loss 0.0169\n",
      "Epoch 12 Batch 2000 Loss 0.0421\n",
      "Epoch 12 Batch 2200 Loss 0.0440\n",
      "Epoch 12 Batch 2400 Loss 0.0222\n",
      "Epoch 12 Loss 0.0247\n",
      "Time taken for 1 epoch 2335.47039604187 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0280\n",
      "Epoch 13 Batch 200 Loss 0.0193\n",
      "Epoch 13 Batch 400 Loss 0.0302\n",
      "Epoch 13 Batch 600 Loss 0.0251\n",
      "Epoch 13 Batch 800 Loss 0.0182\n",
      "Epoch 13 Batch 1000 Loss 0.0244\n",
      "Epoch 13 Batch 1200 Loss 0.0164\n",
      "Epoch 13 Batch 1400 Loss 0.0282\n",
      "Epoch 13 Batch 1600 Loss 0.0254\n",
      "Epoch 13 Batch 1800 Loss 0.0241\n",
      "Epoch 13 Batch 2000 Loss 0.0423\n",
      "Epoch 13 Batch 2200 Loss 0.0384\n",
      "Epoch 13 Batch 2400 Loss 0.0164\n",
      "Epoch 13 Loss 0.0235\n",
      "Time taken for 1 epoch 2312.3772547245026 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0129\n",
      "Epoch 14 Batch 200 Loss 0.0090\n",
      "Epoch 14 Batch 400 Loss 0.0150\n",
      "Epoch 14 Batch 600 Loss 0.0228\n",
      "Epoch 14 Batch 800 Loss 0.0132\n",
      "Epoch 14 Batch 1000 Loss 0.0196\n",
      "Epoch 14 Batch 1200 Loss 0.0489\n",
      "Epoch 14 Batch 1400 Loss 0.0201\n",
      "Epoch 14 Batch 1600 Loss 0.0357\n",
      "Epoch 14 Batch 1800 Loss 0.0313\n",
      "Epoch 14 Batch 2000 Loss 0.0097\n",
      "Epoch 14 Batch 2200 Loss 0.0368\n",
      "Epoch 14 Batch 2400 Loss 0.0408\n",
      "Epoch 14 Loss 0.0237\n",
      "Time taken for 1 epoch 2324.8056564331055 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0117\n",
      "Epoch 15 Batch 200 Loss 0.0163\n",
      "Epoch 15 Batch 400 Loss 0.0095\n",
      "Epoch 15 Batch 600 Loss 0.0240\n",
      "Epoch 15 Batch 800 Loss 0.0206\n",
      "Epoch 15 Batch 1000 Loss 0.0248\n",
      "Epoch 15 Batch 1200 Loss 0.0181\n",
      "Epoch 15 Batch 1400 Loss 0.0217\n",
      "Epoch 15 Batch 1600 Loss 0.0459\n",
      "Epoch 15 Batch 1800 Loss 0.0286\n",
      "Epoch 15 Batch 2000 Loss 0.0154\n",
      "Epoch 15 Batch 2200 Loss 0.0229\n",
      "Epoch 15 Batch 2400 Loss 0.0456\n",
      "Epoch 15 Loss 0.0236\n",
      "Time taken for 1 epoch 2311.6155622005463 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0214\n",
      "Epoch 16 Batch 200 Loss 0.0088\n",
      "Epoch 16 Batch 400 Loss 0.0268\n",
      "Epoch 16 Batch 600 Loss 0.0297\n",
      "Epoch 16 Batch 800 Loss 0.0204\n",
      "Epoch 16 Batch 1000 Loss 0.0165\n",
      "Epoch 16 Batch 1200 Loss 0.0334\n",
      "Epoch 16 Batch 1400 Loss 0.0190\n",
      "Epoch 16 Batch 1600 Loss 0.0324\n",
      "Epoch 16 Batch 1800 Loss 0.0313\n",
      "Epoch 16 Batch 2000 Loss 0.0139\n",
      "Epoch 16 Batch 2200 Loss 0.0327\n",
      "Epoch 16 Batch 2400 Loss 0.0176\n",
      "Epoch 16 Loss 0.0235\n",
      "Time taken for 1 epoch 2314.1266877651215 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0213\n",
      "Epoch 17 Batch 200 Loss 0.0126\n",
      "Epoch 17 Batch 400 Loss 0.0152\n",
      "Epoch 17 Batch 600 Loss 0.0197\n",
      "Epoch 17 Batch 800 Loss 0.0278\n",
      "Epoch 17 Batch 1000 Loss 0.0184\n",
      "Epoch 17 Batch 1200 Loss 0.0165\n",
      "Epoch 17 Batch 1400 Loss 0.0229\n",
      "Epoch 17 Batch 1600 Loss 0.0494\n",
      "Epoch 17 Batch 1800 Loss 0.0140\n",
      "Epoch 17 Batch 2000 Loss 0.0165\n",
      "Epoch 17 Batch 2200 Loss 0.0211\n",
      "Epoch 17 Batch 2400 Loss 0.0403\n",
      "Epoch 17 Loss 0.0225\n",
      "Time taken for 1 epoch 2314.6476612091064 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0167\n",
      "Epoch 18 Batch 200 Loss 0.0230\n",
      "Epoch 18 Batch 400 Loss 0.0336\n",
      "Epoch 18 Batch 600 Loss 0.0241\n",
      "Epoch 18 Batch 800 Loss 0.0230\n",
      "Epoch 18 Batch 1000 Loss 0.0214\n",
      "Epoch 18 Batch 1200 Loss 0.0238\n",
      "Epoch 18 Batch 1400 Loss 0.0192\n",
      "Epoch 18 Batch 1600 Loss 0.0142\n",
      "Epoch 19 Batch 400 Loss 0.0228\n",
      "Epoch 19 Batch 600 Loss 0.0133\n",
      "Epoch 19 Batch 800 Loss 0.0256\n",
      "Epoch 19 Batch 1000 Loss 0.0074\n",
      "Epoch 19 Batch 1200 Loss 0.0156\n",
      "Epoch 19 Batch 1400 Loss 0.0209\n",
      "Epoch 19 Batch 1600 Loss 0.0130\n",
      "Epoch 19 Batch 1800 Loss 0.0236\n",
      "Epoch 19 Batch 2000 Loss 0.0229\n",
      "Epoch 19 Batch 2200 Loss 0.0282\n",
      "Epoch 19 Batch 2400 Loss 0.0252\n",
      "Epoch 19 Loss 0.0226\n",
      "Time taken for 1 epoch 2317.959064245224 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0157\n",
      "Epoch 20 Batch 200 Loss 0.0167\n",
      "Epoch 20 Batch 400 Loss 0.0215\n",
      "Epoch 20 Batch 600 Loss 0.0150\n",
      "Epoch 20 Batch 800 Loss 0.0100\n",
      "Epoch 20 Batch 1000 Loss 0.0161\n",
      "Epoch 20 Batch 1200 Loss 0.0255\n",
      "Epoch 20 Batch 1400 Loss 0.0383\n",
      "Epoch 20 Batch 1600 Loss 0.0473\n",
      "Epoch 20 Batch 1800 Loss 0.0157\n",
      "Epoch 20 Batch 2000 Loss 0.0302\n",
      "Epoch 20 Batch 2200 Loss 0.0157\n",
      "Epoch 20 Batch 2400 Loss 0.0208\n",
      "Epoch 20 Loss 0.0227\n",
      "Time taken for 1 epoch 2325.908639907837 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0090\n",
      "Epoch 21 Batch 200 Loss 0.0020\n",
      "Epoch 21 Batch 400 Loss 0.0253\n",
      "Epoch 21 Batch 600 Loss 0.0217\n",
      "Epoch 21 Batch 800 Loss 0.0200\n",
      "Epoch 21 Batch 1000 Loss 0.0253\n",
      "Epoch 21 Batch 1200 Loss 0.0139\n",
      "Epoch 21 Batch 1400 Loss 0.0433\n",
      "Epoch 21 Batch 1600 Loss 0.0271\n",
      "Epoch 21 Batch 1800 Loss 0.0297\n",
      "Epoch 21 Batch 2000 Loss 0.0262\n",
      "Epoch 21 Batch 2200 Loss 0.0165\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    hidden_h, hidden_c = encoder.initialize_hidden_state()\n",
    "    \n",
    "    hidden = [hidden_h, hidden_c]\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "\n",
    "    code_train_batch = getBatch(code_train, BATCH_SIZE)\n",
    "    \n",
    "    comment_train_batch = getBatch(comment_train, BATCH_SIZE)\n",
    "    \n",
    "    dataset = [(code_train_batch[i], comment_train_batch[i]) for i in range(0, len(code_train_batch))]\n",
    "    \n",
    "    np.random.shuffle(dataset)\n",
    "\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, hidden)\n",
    "            \n",
    "            dec_hidden = [enc_hidden_h, enc_hidden_c]\n",
    "            \n",
    "            dec_input = tf.expand_dims([comment_voc.index('<START>')] * BATCH_SIZE, 1)       \n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden_h, dec_hidden_c, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                dec_hidden = [dec_hidden_h, dec_hidden_c]\n",
    "                \n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        \n",
    "        batch_loss = (loss / int(targ.shape[1]))\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        \n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        if batch % 200 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    lossArray = np.append(lossArray, (total_loss / N_BATCH) )\n",
    "    \n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / N_BATCH))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, EPOCHs+1), lossArray, \"b\", label=\"train\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"Adam Optimizer model loss\")\n",
    "plt.legend(loc = 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 必須解決test set有可能有<UNK>，不然沒辦法translate test set\n",
    "def evaluate(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    tokens_parse = javalang.tokenizer.tokenize(code)\n",
    "    inputs = []\n",
    "    for token in tokens_parse:    # iterate the tokens of the sentence\n",
    "        token = str(token).split(' ')\n",
    "        splitted_id = split_identifier(token[1].strip('\"'))    # split the camelCase and under_score\n",
    "        temp = ['<'+token[0]+'>']    # token[0] is token type, token[1] is token value\n",
    "        temp.extend(splitted_id)\n",
    "        inputs.extend(temp)\n",
    "\n",
    "    inputs.insert(0, '<START>')\n",
    "    inputs.append('<END>')\n",
    "    inputs += ['<PAD>'] * (max_length_inp - len(inputs))\n",
    "    for index, token in enumerate(inputs):\n",
    "        inputs[index] = code_voc.index(token)\n",
    "    inputs = np.array(inputs)\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    \n",
    "    hidden_h, hidden_c = tf.zeros((1, units)), tf.zeros((1, units))\n",
    "    \n",
    "    hidden = [hidden_h, hidden_c]\n",
    "\n",
    "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inputs, hidden)\n",
    "    dec_hidden = [enc_hidden_h, enc_hidden_c]\n",
    "    dec_input = tf.expand_dims([comment_voc.index('<START>')], 1)       \n",
    "    \n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden_h, dec_hidden_c, attention_weights = decoder(dec_input, dec_hidden, enc_output)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += comment_voc[predicted_id] + ' '\n",
    "\n",
    "        if comment_voc[predicted_id] == '<END>':\n",
    "            return result, code, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, code, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ):\n",
    "    result, code, attention_plot = evaluate(code, encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(code))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    print(type(attention_plot))\n",
    "    #attention_plot = attention_plot[:len(result.split(' ')), :len(code.split(' '))]\n",
    "    #plot_attention(attention_plot, code.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fbc282f23c8>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./filter_dataset/filter_train.json')\n",
    "inputs = f.readlines()\n",
    "f.close()\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "for pair in inputs[:20]:\n",
    "    pair = json.loads(pair)\n",
    "    test_inputs.append(pair['code'])\n",
    "    test_outputs.append(pair['nl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creates a share intent'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(test_inputs[7])\n",
    "test_outputs[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: private static Intent createShareIntent(Context context,final String shareText){\n",
      "  final Intent shareIntent=new Intent(Intent.ACTION_SEND);\n",
      "  shareIntent.putExtra(android.content.Intent.EXTRA_SUBJECT,context.getString(R.string.share_subject));\n",
      "  shareIntent.putExtra(android.content.Intent.EXTRA_TEXT,shareText);\n",
      "  shareIntent.setType(\"text/plain\");\n",
      "  return shareIntent;\n",
      "}\n",
      "\n",
      "Predicted translation: a new protocol is useful for no matches a new protocol is useful for no matches a new protocol is useful for no matches a new protocol is useful for \n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "translate(test_inputs[14], encoder, decoder, code_voc, comment_voc, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
